{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7084085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accepted</th>\n",
       "      <th>actually</th>\n",
       "      <th>afar</th>\n",
       "      <th>africa</th>\n",
       "      <th>aging</th>\n",
       "      <th>ago</th>\n",
       "      <th>air</th>\n",
       "      <th>alcoholic</th>\n",
       "      <th>align</th>\n",
       "      <th>allah</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>written</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accepted  actually  afar  africa  aging  ago  air  alcoholic  align  \\\n",
       "0           0         0     0       0      0    0    0          0      0   \n",
       "1           0         0     0       0      0    0    0          0      0   \n",
       "2           0         0     0       0      0    0    0          0      0   \n",
       "3           0         0     0       0      0    0    0          0      0   \n",
       "4           0         0     0       0      0    0    0          0      0   \n",
       "..        ...       ...   ...     ...    ...  ...  ...        ...    ...   \n",
       "170         0         0     0       0      0    0    0          0      0   \n",
       "171         0         0     0       0      0    0    0          0      0   \n",
       "172         0         0     0       0      0    0    0          0      0   \n",
       "173         0         0     0       0      0    0    0          0      0   \n",
       "174         0         0     0       0      0    0    0          0      0   \n",
       "\n",
       "     allah  ...  world  worried  worse  worst  write  writer  written  wrote  \\\n",
       "0        0  ...      0        0      0      0      0       1        0      0   \n",
       "1        0  ...      0        0      0      0      0       0        0      0   \n",
       "2        0  ...      0        0      0      0      0       0        0      0   \n",
       "3        0  ...      0        0      0      0      0       0        0      0   \n",
       "4        0  ...      0        0      0      0      0       0        0      0   \n",
       "..     ...  ...    ...      ...    ...    ...    ...     ...      ...    ...   \n",
       "170      0  ...      0        0      0      0      0       0        0      0   \n",
       "171      0  ...      0        0      0      0      0       0        0      0   \n",
       "172      0  ...      0        0      0      0      0       0        0      0   \n",
       "173      0  ...      0        0      0      0      0       0        0      0   \n",
       "174      0  ...      0        0      0      0      0       0        0      0   \n",
       "\n",
       "     yes  young  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "..   ...    ...  \n",
       "170    0      0  \n",
       "171    0      0  \n",
       "172    0      0  \n",
       "173    0      0  \n",
       "174    0      0  \n",
       "\n",
       "[175 rows x 572 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef8f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d76bb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accepted</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actually</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afar</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>africa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aging</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9    ...  165  166  \\\n",
       "accepted    0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "actually    0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "afar        0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "africa      0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "aging       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
       "\n",
       "          167  168  169  170  171  172  173  174  \n",
       "accepted    0    0    0    0    0    0    0    0  \n",
       "actually    0    0    0    0    0    0    0    0  \n",
       "afar        0    0    0    0    0    0    0    0  \n",
       "africa      0    0    0    0    0    0    0    0  \n",
       "aging       0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036311f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aeee5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22350489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:09,319 : INFO : using symmetric alpha at 0.5\n",
      "2022-05-06 23:31:09,322 : INFO : using symmetric eta at 0.5\n",
      "2022-05-06 23:31:09,322 : INFO : using serial LDA version on this node\n",
      "2022-05-06 23:31:09,328 : INFO : running online (multi-pass) LDA training, 2 topics, 10 passes over the supplied corpus of 175 documents, updating model once every 175 documents, evaluating perplexity every 175 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-05-06 23:31:09,437 : INFO : -7.248 per-word bound, 152.0 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,438 : INFO : PROGRESS: pass 0, at document #175/175\n",
      "2022-05-06 23:31:09,518 : INFO : topic #0 (0.500): 0.013*\"ve\" + 0.007*\"allah\" + 0.007*\"artist\" + 0.007*\"dance\" + 0.006*\"idea\" + 0.006*\"tom\" + 0.005*\"divine\" + 0.005*\"started\" + 0.005*\"century\" + 0.005*\"called\"\n",
      "2022-05-06 23:31:09,520 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.007*\"make\" + 0.006*\"writer\" + 0.006*\"ancient\" + 0.006*\"believe\" + 0.006*\"somebody\" + 0.005*\"question\" + 0.005*\"lit\" + 0.005*\"allah\" + 0.005*\"feel\"\n",
      "2022-05-06 23:31:09,520 : INFO : topic diff=0.639809, rho=1.000000\n",
      "2022-05-06 23:31:09,568 : INFO : -6.836 per-word bound, 114.2 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,568 : INFO : PROGRESS: pass 1, at document #175/175\n",
      "2022-05-06 23:31:09,605 : INFO : topic #0 (0.500): 0.013*\"ve\" + 0.008*\"artist\" + 0.007*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"idea\" + 0.005*\"divine\" + 0.005*\"century\" + 0.005*\"started\" + 0.005*\"called\"\n",
      "2022-05-06 23:31:09,607 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.008*\"make\" + 0.006*\"ancient\" + 0.006*\"question\" + 0.006*\"believe\" + 0.006*\"writer\" + 0.006*\"somebody\" + 0.005*\"feel\" + 0.005*\"lit\" + 0.005*\"happen\"\n",
      "2022-05-06 23:31:09,607 : INFO : topic diff=0.186854, rho=0.577350\n",
      "2022-05-06 23:31:09,647 : INFO : -6.785 per-word bound, 110.3 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,647 : INFO : PROGRESS: pass 2, at document #175/175\n",
      "2022-05-06 23:31:09,677 : INFO : topic #0 (0.500): 0.014*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"idea\" + 0.006*\"century\" + 0.006*\"divine\" + 0.006*\"started\" + 0.005*\"believed\"\n",
      "2022-05-06 23:31:09,678 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.007*\"question\" + 0.007*\"ancient\" + 0.007*\"believe\" + 0.006*\"writer\" + 0.006*\"somebody\" + 0.006*\"feel\" + 0.005*\"lit\" + 0.005*\"happen\"\n",
      "2022-05-06 23:31:09,678 : INFO : topic diff=0.097008, rho=0.500000\n",
      "2022-05-06 23:31:09,715 : INFO : -6.768 per-word bound, 109.0 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,715 : INFO : PROGRESS: pass 3, at document #175/175\n",
      "2022-05-06 23:31:09,742 : INFO : topic #0 (0.500): 0.014*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"idea\" + 0.006*\"century\" + 0.006*\"divine\" + 0.006*\"started\" + 0.006*\"believed\"\n",
      "2022-05-06 23:31:09,742 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.007*\"question\" + 0.007*\"ancient\" + 0.007*\"believe\" + 0.006*\"writer\" + 0.006*\"somebody\" + 0.006*\"feel\" + 0.005*\"chemical\" + 0.005*\"anybody\"\n",
      "2022-05-06 23:31:09,743 : INFO : topic diff=0.054069, rho=0.447214\n",
      "2022-05-06 23:31:09,778 : INFO : -6.761 per-word bound, 108.5 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,779 : INFO : PROGRESS: pass 4, at document #175/175\n",
      "2022-05-06 23:31:09,803 : INFO : topic #0 (0.500): 0.014*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"idea\" + 0.006*\"believed\" + 0.006*\"divine\" + 0.006*\"started\"\n",
      "2022-05-06 23:31:09,803 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.007*\"ancient\" + 0.007*\"believe\" + 0.006*\"writer\" + 0.006*\"somebody\" + 0.006*\"feel\" + 0.005*\"anybody\" + 0.005*\"chemical\"\n",
      "2022-05-06 23:31:09,804 : INFO : topic diff=0.032698, rho=0.408248\n",
      "2022-05-06 23:31:09,837 : INFO : -6.758 per-word bound, 108.2 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,838 : INFO : PROGRESS: pass 5, at document #175/175\n",
      "2022-05-06 23:31:09,866 : INFO : topic #0 (0.500): 0.014*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"believed\" + 0.006*\"idea\" + 0.006*\"divine\" + 0.006*\"called\"\n",
      "2022-05-06 23:31:09,867 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.007*\"ancient\" + 0.007*\"believe\" + 0.006*\"somebody\" + 0.006*\"writer\" + 0.006*\"feel\" + 0.005*\"anybody\" + 0.005*\"chemical\"\n",
      "2022-05-06 23:31:09,867 : INFO : topic diff=0.021592, rho=0.377964\n",
      "2022-05-06 23:31:09,902 : INFO : -6.756 per-word bound, 108.1 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,902 : INFO : PROGRESS: pass 6, at document #175/175\n",
      "2022-05-06 23:31:09,926 : INFO : topic #0 (0.500): 0.015*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"believed\" + 0.006*\"divine\" + 0.006*\"idea\" + 0.006*\"called\"\n",
      "2022-05-06 23:31:09,927 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.008*\"ancient\" + 0.007*\"believe\" + 0.006*\"feel\" + 0.006*\"somebody\" + 0.006*\"writer\" + 0.006*\"anybody\" + 0.005*\"chemical\"\n",
      "2022-05-06 23:31:09,927 : INFO : topic diff=0.015359, rho=0.353553\n",
      "2022-05-06 23:31:09,962 : INFO : -6.754 per-word bound, 107.9 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:09,962 : INFO : PROGRESS: pass 7, at document #175/175\n",
      "2022-05-06 23:31:09,985 : INFO : topic #0 (0.500): 0.015*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"believed\" + 0.006*\"divine\" + 0.006*\"talking\" + 0.006*\"called\"\n",
      "2022-05-06 23:31:09,985 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.008*\"ancient\" + 0.007*\"believe\" + 0.006*\"feel\" + 0.006*\"somebody\" + 0.006*\"writer\" + 0.006*\"anybody\" + 0.005*\"chemical\"\n",
      "2022-05-06 23:31:09,986 : INFO : topic diff=0.011469, rho=0.333333\n",
      "2022-05-06 23:31:10,018 : INFO : -6.752 per-word bound, 107.8 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,018 : INFO : PROGRESS: pass 8, at document #175/175\n",
      "2022-05-06 23:31:10,042 : INFO : topic #0 (0.500): 0.015*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"believed\" + 0.006*\"divine\" + 0.006*\"talking\" + 0.006*\"called\"\n",
      "2022-05-06 23:31:10,042 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.008*\"ancient\" + 0.007*\"believe\" + 0.007*\"feel\" + 0.006*\"somebody\" + 0.006*\"writer\" + 0.006*\"anybody\" + 0.005*\"chemical\"\n",
      "2022-05-06 23:31:10,043 : INFO : topic diff=0.008916, rho=0.316228\n",
      "2022-05-06 23:31:10,077 : INFO : -6.751 per-word bound, 107.7 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,077 : INFO : PROGRESS: pass 9, at document #175/175\n",
      "2022-05-06 23:31:10,099 : INFO : topic #0 (0.500): 0.015*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"believed\" + 0.006*\"divine\" + 0.006*\"talking\" + 0.006*\"called\"\n",
      "2022-05-06 23:31:10,099 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.008*\"ancient\" + 0.008*\"believe\" + 0.007*\"feel\" + 0.006*\"somebody\" + 0.006*\"writer\" + 0.006*\"anybody\" + 0.006*\"chemical\"\n",
      "2022-05-06 23:31:10,100 : INFO : topic diff=0.007272, rho=0.301511\n",
      "2022-05-06 23:31:10,100 : INFO : topic #0 (0.500): 0.015*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"believed\" + 0.006*\"divine\" + 0.006*\"talking\" + 0.006*\"called\"\n",
      "2022-05-06 23:31:10,101 : INFO : topic #1 (0.500): 0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.008*\"ancient\" + 0.008*\"believe\" + 0.007*\"feel\" + 0.006*\"somebody\" + 0.006*\"writer\" + 0.006*\"anybody\" + 0.006*\"chemical\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"ve\" + 0.008*\"artist\" + 0.008*\"dance\" + 0.007*\"allah\" + 0.007*\"tom\" + 0.006*\"century\" + 0.006*\"believed\" + 0.006*\"divine\" + 0.006*\"talking\" + 0.006*\"called\"'),\n",
       " (1,\n",
       "  '0.009*\"god\" + 0.009*\"make\" + 0.008*\"question\" + 0.008*\"ancient\" + 0.008*\"believe\" + 0.007*\"feel\" + 0.006*\"somebody\" + 0.006*\"writer\" + 0.006*\"anybody\" + 0.006*\"chemical\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59fe173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:10,119 : INFO : using symmetric alpha at 0.25\n",
      "2022-05-06 23:31:10,121 : INFO : using symmetric eta at 0.25\n",
      "2022-05-06 23:31:10,121 : INFO : using serial LDA version on this node\n",
      "2022-05-06 23:31:10,122 : INFO : running online (multi-pass) LDA training, 4 topics, 10 passes over the supplied corpus of 175 documents, updating model once every 175 documents, evaluating perplexity every 175 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-05-06 23:31:10,193 : INFO : -8.607 per-word bound, 389.8 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,193 : INFO : PROGRESS: pass 0, at document #175/175\n",
      "2022-05-06 23:31:10,254 : INFO : topic #0 (0.250): 0.009*\"believed\" + 0.009*\"idea\" + 0.009*\"lit\" + 0.009*\"question\" + 0.007*\"unknowable\" + 0.007*\"source\" + 0.007*\"believe\" + 0.006*\"ancient\" + 0.006*\"started\" + 0.006*\"extraordinary\"\n",
      "2022-05-06 23:31:10,255 : INFO : topic #1 (0.250): 0.018*\"ve\" + 0.011*\"job\" + 0.009*\"doomed\" + 0.009*\"hell\" + 0.008*\"talking\" + 0.008*\"internalized\" + 0.007*\"somebody\" + 0.007*\"idea\" + 0.006*\"released\" + 0.006*\"dance\"\n",
      "2022-05-06 23:31:10,256 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.010*\"artist\" + 0.010*\"changed\" + 0.009*\"century\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"writer\" + 0.009*\"continue\" + 0.009*\"allah\" + 0.008*\"got\"\n",
      "2022-05-06 23:31:10,257 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.014*\"allah\" + 0.012*\"ve\" + 0.011*\"make\" + 0.011*\"love\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.008*\"applause\" + 0.006*\"engineer\" + 0.006*\"question\"\n",
      "2022-05-06 23:31:10,258 : INFO : topic diff=2.308351, rho=1.000000\n",
      "2022-05-06 23:31:10,290 : INFO : -7.026 per-word bound, 130.4 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,291 : INFO : PROGRESS: pass 1, at document #175/175\n",
      "2022-05-06 23:31:10,313 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.009*\"lit\" + 0.009*\"question\" + 0.008*\"believed\" + 0.007*\"unknowable\" + 0.007*\"believe\" + 0.007*\"source\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"spirit\"\n",
      "2022-05-06 23:31:10,314 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.009*\"doomed\" + 0.008*\"hell\" + 0.008*\"talking\" + 0.008*\"internalized\" + 0.008*\"somebody\" + 0.008*\"idea\" + 0.006*\"released\" + 0.006*\"dance\"\n",
      "2022-05-06 23:31:10,314 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.011*\"artist\" + 0.009*\"changed\" + 0.009*\"century\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"writer\" + 0.009*\"continue\" + 0.009*\"allah\" + 0.009*\"got\"\n",
      "2022-05-06 23:31:10,315 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"ve\" + 0.011*\"make\" + 0.011*\"love\" + 0.009*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"engineer\" + 0.006*\"question\"\n",
      "2022-05-06 23:31:10,315 : INFO : topic diff=0.099489, rho=0.577350\n",
      "2022-05-06 23:31:10,349 : INFO : -6.995 per-word bound, 127.6 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,350 : INFO : PROGRESS: pass 2, at document #175/175\n",
      "2022-05-06 23:31:10,371 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"believed\" + 0.007*\"unknowable\" + 0.007*\"believe\" + 0.007*\"source\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"great\"\n",
      "2022-05-06 23:31:10,372 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"talking\" + 0.008*\"internalized\" + 0.008*\"somebody\" + 0.008*\"idea\" + 0.006*\"released\" + 0.006*\"dance\"\n",
      "2022-05-06 23:31:10,373 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.011*\"artist\" + 0.009*\"changed\" + 0.009*\"century\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"writer\" + 0.009*\"continue\" + 0.009*\"allah\" + 0.009*\"got\"\n",
      "2022-05-06 23:31:10,374 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"ve\" + 0.011*\"make\" + 0.011*\"love\" + 0.010*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"engineer\" + 0.006*\"question\"\n",
      "2022-05-06 23:31:10,375 : INFO : topic diff=0.046576, rho=0.500000\n",
      "2022-05-06 23:31:10,412 : INFO : -6.986 per-word bound, 126.8 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,412 : INFO : PROGRESS: pass 3, at document #175/175\n",
      "2022-05-06 23:31:10,436 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"believed\" + 0.007*\"unknowable\" + 0.007*\"believe\" + 0.007*\"source\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"great\"\n",
      "2022-05-06 23:31:10,438 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"talking\" + 0.008*\"internalized\" + 0.008*\"somebody\" + 0.008*\"idea\" + 0.006*\"dance\" + 0.006*\"released\"\n",
      "2022-05-06 23:31:10,439 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"changed\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"writer\" + 0.009*\"allah\" + 0.009*\"got\"\n",
      "2022-05-06 23:31:10,441 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"ve\" + 0.011*\"make\" + 0.011*\"love\" + 0.010*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"question\" + 0.006*\"engineer\"\n",
      "2022-05-06 23:31:10,441 : INFO : topic diff=0.024332, rho=0.447214\n",
      "2022-05-06 23:31:10,472 : INFO : -6.984 per-word bound, 126.6 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,473 : INFO : PROGRESS: pass 4, at document #175/175\n",
      "2022-05-06 23:31:10,493 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"believed\" + 0.007*\"believe\" + 0.007*\"unknowable\" + 0.007*\"source\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"great\"\n",
      "2022-05-06 23:31:10,494 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"talking\" + 0.008*\"somebody\" + 0.008*\"internalized\" + 0.008*\"idea\" + 0.006*\"dance\" + 0.006*\"released\"\n",
      "2022-05-06 23:31:10,495 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"changed\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"writer\" + 0.009*\"allah\" + 0.009*\"got\"\n",
      "2022-05-06 23:31:10,496 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"ve\" + 0.011*\"love\" + 0.010*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"question\" + 0.006*\"dancer\"\n",
      "2022-05-06 23:31:10,497 : INFO : topic diff=0.013545, rho=0.408248\n",
      "2022-05-06 23:31:10,529 : INFO : -6.983 per-word bound, 126.5 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,529 : INFO : PROGRESS: pass 5, at document #175/175\n",
      "2022-05-06 23:31:10,550 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"believed\" + 0.007*\"believe\" + 0.007*\"started\" + 0.007*\"unknowable\" + 0.007*\"source\" + 0.007*\"extraordinary\" + 0.007*\"great\"\n",
      "2022-05-06 23:31:10,551 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"somebody\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"talking\" + 0.008*\"internalized\" + 0.008*\"idea\" + 0.006*\"dance\" + 0.006*\"released\"\n",
      "2022-05-06 23:31:10,551 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"changed\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"writer\" + 0.009*\"allah\" + 0.009*\"got\"\n",
      "2022-05-06 23:31:10,552 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"love\" + 0.011*\"ve\" + 0.011*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"question\" + 0.006*\"dancer\"\n",
      "2022-05-06 23:31:10,552 : INFO : topic diff=0.007901, rho=0.377964\n",
      "2022-05-06 23:31:10,590 : INFO : -6.982 per-word bound, 126.4 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,591 : INFO : PROGRESS: pass 6, at document #175/175\n",
      "2022-05-06 23:31:10,610 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"believed\" + 0.007*\"started\" + 0.007*\"believe\" + 0.007*\"extraordinary\" + 0.007*\"unknowable\" + 0.007*\"source\" + 0.007*\"great\"\n",
      "2022-05-06 23:31:10,611 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"somebody\" + 0.008*\"talking\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"internalized\" + 0.008*\"idea\" + 0.006*\"dance\" + 0.006*\"released\"\n",
      "2022-05-06 23:31:10,611 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"changed\" + 0.009*\"brilliant\" + 0.009*\"got\" + 0.009*\"reputation\" + 0.009*\"allah\" + 0.009*\"continue\" + 0.009*\"writer\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:10,612 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"love\" + 0.011*\"ve\" + 0.011*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"dance\" + 0.006*\"question\"\n",
      "2022-05-06 23:31:10,613 : INFO : topic diff=0.004789, rho=0.353553\n",
      "2022-05-06 23:31:10,649 : INFO : -6.982 per-word bound, 126.4 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,650 : INFO : PROGRESS: pass 7, at document #175/175\n",
      "2022-05-06 23:31:10,673 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"believed\" + 0.007*\"believe\" + 0.007*\"great\" + 0.007*\"source\" + 0.007*\"unknowable\"\n",
      "2022-05-06 23:31:10,674 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"somebody\" + 0.008*\"talking\" + 0.008*\"idea\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"internalized\" + 0.006*\"dance\" + 0.006*\"better\"\n",
      "2022-05-06 23:31:10,674 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"got\" + 0.009*\"changed\" + 0.009*\"brilliant\" + 0.009*\"allah\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"writer\"\n",
      "2022-05-06 23:31:10,674 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"love\" + 0.011*\"ve\" + 0.011*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"dance\" + 0.006*\"question\"\n",
      "2022-05-06 23:31:10,675 : INFO : topic diff=0.002999, rho=0.333333\n",
      "2022-05-06 23:31:10,709 : INFO : -6.982 per-word bound, 126.4 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,709 : INFO : PROGRESS: pass 8, at document #175/175\n",
      "2022-05-06 23:31:10,729 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"believe\" + 0.007*\"great\" + 0.007*\"believed\" + 0.007*\"source\" + 0.007*\"unknowable\"\n",
      "2022-05-06 23:31:10,730 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"somebody\" + 0.008*\"idea\" + 0.008*\"talking\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"internalized\" + 0.006*\"dance\" + 0.006*\"better\"\n",
      "2022-05-06 23:31:10,739 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"got\" + 0.009*\"allah\" + 0.009*\"brilliant\" + 0.009*\"changed\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"writer\"\n",
      "2022-05-06 23:31:10,740 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"love\" + 0.011*\"ve\" + 0.011*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"dance\" + 0.006*\"question\"\n",
      "2022-05-06 23:31:10,742 : INFO : topic diff=0.001932, rho=0.316228\n",
      "2022-05-06 23:31:10,786 : INFO : -6.982 per-word bound, 126.4 perplexity estimate based on a held-out corpus of 175 documents with 902 words\n",
      "2022-05-06 23:31:10,787 : INFO : PROGRESS: pass 9, at document #175/175\n",
      "2022-05-06 23:31:10,812 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"believe\" + 0.007*\"great\" + 0.007*\"source\" + 0.007*\"believed\" + 0.007*\"unknowable\"\n",
      "2022-05-06 23:31:10,812 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"somebody\" + 0.008*\"idea\" + 0.008*\"talking\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"internalized\" + 0.006*\"mystery\" + 0.006*\"better\"\n",
      "2022-05-06 23:31:10,813 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"got\" + 0.009*\"allah\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"changed\" + 0.009*\"writer\"\n",
      "2022-05-06 23:31:10,814 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"love\" + 0.011*\"ve\" + 0.011*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"dance\" + 0.006*\"dancer\"\n",
      "2022-05-06 23:31:10,814 : INFO : topic diff=0.001276, rho=0.301511\n",
      "2022-05-06 23:31:10,815 : INFO : topic #0 (0.250): 0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"believe\" + 0.007*\"great\" + 0.007*\"source\" + 0.007*\"believed\" + 0.007*\"unknowable\"\n",
      "2022-05-06 23:31:10,815 : INFO : topic #1 (0.250): 0.019*\"ve\" + 0.011*\"job\" + 0.008*\"somebody\" + 0.008*\"idea\" + 0.008*\"talking\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"internalized\" + 0.006*\"mystery\" + 0.006*\"better\"\n",
      "2022-05-06 23:31:10,816 : INFO : topic #2 (0.250): 0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"got\" + 0.009*\"allah\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"changed\" + 0.009*\"writer\"\n",
      "2022-05-06 23:31:10,816 : INFO : topic #3 (0.250): 0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"love\" + 0.011*\"ve\" + 0.011*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"dance\" + 0.006*\"dancer\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"idea\" + 0.010*\"lit\" + 0.010*\"question\" + 0.007*\"started\" + 0.007*\"extraordinary\" + 0.007*\"believe\" + 0.007*\"great\" + 0.007*\"source\" + 0.007*\"believed\" + 0.007*\"unknowable\"'),\n",
       " (1,\n",
       "  '0.019*\"ve\" + 0.011*\"job\" + 0.008*\"somebody\" + 0.008*\"idea\" + 0.008*\"talking\" + 0.008*\"doomed\" + 0.008*\"hell\" + 0.008*\"internalized\" + 0.006*\"mystery\" + 0.006*\"better\"'),\n",
       " (2,\n",
       "  '0.012*\"ancient\" + 0.012*\"artist\" + 0.009*\"century\" + 0.009*\"got\" + 0.009*\"allah\" + 0.009*\"brilliant\" + 0.009*\"reputation\" + 0.009*\"continue\" + 0.009*\"changed\" + 0.009*\"writer\"'),\n",
       " (3,\n",
       "  '0.018*\"god\" + 0.013*\"allah\" + 0.011*\"make\" + 0.011*\"love\" + 0.011*\"ve\" + 0.011*\"applause\" + 0.008*\"chemical\" + 0.008*\"career\" + 0.006*\"dance\" + 0.006*\"dancer\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b6dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77935955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>writing book profession s  course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it also great lifelong love fascination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and i nt expect s ever going change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>but  said  something kind peculiar happened re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>nonetheless  sheer human love stubbornness ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>applause   thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>applause   june cohen  olé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>applause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript\n",
       "0                                            i writer \n",
       "1                   writing book profession s  course \n",
       "2             it also great lifelong love fascination \n",
       "3                 and i nt expect s ever going change \n",
       "4    but  said  something kind peculiar happened re...\n",
       "..                                                 ...\n",
       "170   nonetheless  sheer human love stubbornness ke...\n",
       "171                                             thank \n",
       "172                                  applause   thank \n",
       "173                        applause   june cohen  olé \n",
       "174                                          applause \n",
       "\n",
       "[175 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b8af06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book profession s course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love fascination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nt change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>something kind life career relationship work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>sheer love stubbornness showing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>applause thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>applause june cohen olé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>applause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcript\n",
       "0                                          writer\n",
       "1                        book profession s course\n",
       "2                                love fascination\n",
       "3                                       nt change\n",
       "4    something kind life career relationship work\n",
       "..                                            ...\n",
       "170               sheer love stubbornness showing\n",
       "171                                         thank\n",
       "172                                applause thank\n",
       "173                       applause june cohen olé\n",
       "174                                      applause\n",
       "\n",
       "[175 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009ca2b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afar</th>\n",
       "      <th>afraid</th>\n",
       "      <th>air</th>\n",
       "      <th>allah</th>\n",
       "      <th>ancient</th>\n",
       "      <th>angeles</th>\n",
       "      <th>anguish</th>\n",
       "      <th>answer</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>anybody</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>wonderment</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>writer</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     afar  afraid  air  allah  ancient  angeles  anguish  answer  anxiety  \\\n",
       "0       0       0    0      0        0        0        0       0        0   \n",
       "1       0       0    0      0        0        0        0       0        0   \n",
       "2       0       0    0      0        0        0        0       0        0   \n",
       "3       0       0    0      0        0        0        0       0        0   \n",
       "4       0       0    0      0        0        0        0       0        0   \n",
       "..    ...     ...  ...    ...      ...      ...      ...     ...      ...   \n",
       "170     0       0    0      0        0        0        0       0        0   \n",
       "171     0       0    0      0        0        0        0       0        0   \n",
       "172     0       0    0      0        0        0        0       0        0   \n",
       "173     0       0    0      0        0        0        0       0        0   \n",
       "174     0       0    0      0        0        0        0       0        0   \n",
       "\n",
       "     anybody  ...  way  wisdom  wonderment  word  work  world  worried  \\\n",
       "0          0  ...    0       0           0     0     0      0        0   \n",
       "1          0  ...    0       0           0     0     0      0        0   \n",
       "2          0  ...    0       0           0     0     0      0        0   \n",
       "3          0  ...    0       0           0     0     0      0        0   \n",
       "4          0  ...    0       0           0     0     1      0        0   \n",
       "..       ...  ...  ...     ...         ...   ...   ...    ...      ...   \n",
       "170        0  ...    0       0           0     0     0      0        0   \n",
       "171        0  ...    0       0           0     0     0      0        0   \n",
       "172        0  ...    0       0           0     0     0      0        0   \n",
       "173        0  ...    0       0           0     0     0      0        0   \n",
       "174        0  ...    0       0           0     0     0      0        0   \n",
       "\n",
       "     writer  year  yes  \n",
       "0         1     0    0  \n",
       "1         0     0    0  \n",
       "2         0     0    0  \n",
       "3         0     0    0  \n",
       "4         0     0    0  \n",
       "..      ...   ...  ...  \n",
       "170       0     0    0  \n",
       "171       0     0    0  \n",
       "172       0     0    0  \n",
       "173       0     0    0  \n",
       "174       0     0    0  \n",
       "\n",
       "[175 rows x 292 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6e9ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32882e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:11,539 : INFO : using symmetric alpha at 0.25\n",
      "2022-05-06 23:31:11,542 : INFO : using symmetric eta at 0.25\n",
      "2022-05-06 23:31:11,548 : INFO : using serial LDA version on this node\n",
      "2022-05-06 23:31:11,550 : INFO : running online (multi-pass) LDA training, 4 topics, 10 passes over the supplied corpus of 175 documents, updating model once every 175 documents, evaluating perplexity every 175 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-05-06 23:31:11,614 : INFO : -7.798 per-word bound, 222.5 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:11,615 : INFO : PROGRESS: pass 0, at document #175/175\n",
      "2022-05-06 23:31:11,663 : INFO : topic #0 (0.250): 0.034*\"work\" + 0.026*\"way\" + 0.025*\"sort\" + 0.025*\"life\" + 0.025*\"olé\" + 0.017*\"kind\" + 0.013*\"allah\" + 0.013*\"artist\" + 0.013*\"divine\" + 0.009*\"house\"\n",
      "2022-05-06 23:31:11,664 : INFO : topic #1 (0.250): 0.036*\"thing\" + 0.021*\"god\" + 0.021*\"year\" + 0.016*\"book\" + 0.016*\"sort\" + 0.016*\"allah\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"applause\" + 0.011*\"anxiety\"\n",
      "2022-05-06 23:31:11,665 : INFO : topic #2 (0.250): 0.032*\"thing\" + 0.023*\"kind\" + 0.023*\"work\" + 0.023*\"nt\" + 0.023*\"dance\" + 0.019*\"sort\" + 0.019*\"book\" + 0.019*\"laughter\" + 0.014*\"idea\" + 0.014*\"life\"\n",
      "2022-05-06 23:31:11,665 : INFO : topic #3 (0.250): 0.023*\"work\" + 0.017*\"laughter\" + 0.017*\"chemical\" + 0.017*\"anybody\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"process\" + 0.017*\"question\" + 0.012*\"book\" + 0.012*\"idea\"\n",
      "2022-05-06 23:31:11,666 : INFO : topic diff=2.403079, rho=1.000000\n",
      "2022-05-06 23:31:11,699 : INFO : -6.287 per-word bound, 78.1 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:11,699 : INFO : PROGRESS: pass 1, at document #175/175\n",
      "2022-05-06 23:31:11,721 : INFO : topic #0 (0.250): 0.039*\"work\" + 0.026*\"way\" + 0.026*\"sort\" + 0.026*\"life\" + 0.026*\"olé\" + 0.017*\"kind\" + 0.013*\"allah\" + 0.013*\"artist\" + 0.013*\"divine\" + 0.009*\"house\"\n",
      "2022-05-06 23:31:11,722 : INFO : topic #1 (0.250): 0.038*\"thing\" + 0.024*\"god\" + 0.021*\"year\" + 0.016*\"book\" + 0.016*\"genius\" + 0.016*\"sort\" + 0.016*\"allah\" + 0.016*\"somebody\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:11,723 : INFO : topic #2 (0.250): 0.030*\"thing\" + 0.026*\"nt\" + 0.024*\"kind\" + 0.023*\"dance\" + 0.021*\"laughter\" + 0.021*\"book\" + 0.019*\"sort\" + 0.018*\"work\" + 0.015*\"idea\" + 0.014*\"reputation\"\n",
      "2022-05-06 23:31:11,723 : INFO : topic #3 (0.250): 0.023*\"process\" + 0.022*\"work\" + 0.017*\"laughter\" + 0.017*\"anybody\" + 0.017*\"chemical\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"book\"\n",
      "2022-05-06 23:31:11,723 : INFO : topic diff=0.066336, rho=0.577350\n",
      "2022-05-06 23:31:11,756 : INFO : -6.272 per-word bound, 77.3 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:11,756 : INFO : PROGRESS: pass 2, at document #175/175\n",
      "2022-05-06 23:31:11,780 : INFO : topic #0 (0.250): 0.041*\"work\" + 0.026*\"way\" + 0.026*\"sort\" + 0.026*\"life\" + 0.026*\"olé\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:11,781 : INFO : topic #1 (0.250): 0.042*\"thing\" + 0.025*\"god\" + 0.021*\"year\" + 0.018*\"sort\" + 0.016*\"book\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:11,781 : INFO : topic #2 (0.250): 0.027*\"nt\" + 0.027*\"thing\" + 0.024*\"kind\" + 0.024*\"dance\" + 0.023*\"book\" + 0.022*\"laughter\" + 0.017*\"sort\" + 0.016*\"work\" + 0.015*\"success\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:11,782 : INFO : topic #3 (0.250): 0.025*\"process\" + 0.022*\"work\" + 0.017*\"laughter\" + 0.017*\"anybody\" + 0.017*\"chemical\" + 0.017*\"poem\" + 0.017*\"question\" + 0.017*\"creativity\" + 0.012*\"idea\" + 0.012*\"engineer\"\n",
      "2022-05-06 23:31:11,782 : INFO : topic diff=0.030163, rho=0.500000\n",
      "2022-05-06 23:31:11,816 : INFO : -6.265 per-word bound, 76.9 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:11,817 : INFO : PROGRESS: pass 3, at document #175/175\n",
      "2022-05-06 23:31:11,839 : INFO : topic #0 (0.250): 0.042*\"work\" + 0.026*\"way\" + 0.026*\"sort\" + 0.026*\"life\" + 0.026*\"olé\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:11,841 : INFO : topic #1 (0.250): 0.043*\"thing\" + 0.025*\"god\" + 0.021*\"year\" + 0.019*\"sort\" + 0.016*\"book\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:11,841 : INFO : topic #2 (0.250): 0.028*\"nt\" + 0.025*\"thing\" + 0.025*\"book\" + 0.024*\"kind\" + 0.024*\"dance\" + 0.023*\"laughter\" + 0.016*\"success\" + 0.016*\"sort\" + 0.015*\"work\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:11,842 : INFO : topic #3 (0.250): 0.027*\"process\" + 0.022*\"work\" + 0.017*\"anybody\" + 0.017*\"laughter\" + 0.017*\"chemical\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n",
      "2022-05-06 23:31:11,842 : INFO : topic diff=0.016322, rho=0.447214\n",
      "2022-05-06 23:31:11,875 : INFO : -6.262 per-word bound, 76.8 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:11,876 : INFO : PROGRESS: pass 4, at document #175/175\n",
      "2022-05-06 23:31:11,896 : INFO : topic #0 (0.250): 0.042*\"work\" + 0.026*\"way\" + 0.026*\"life\" + 0.026*\"sort\" + 0.026*\"olé\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:11,897 : INFO : topic #1 (0.250): 0.044*\"thing\" + 0.025*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"book\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:11,898 : INFO : topic #2 (0.250): 0.028*\"nt\" + 0.026*\"book\" + 0.025*\"kind\" + 0.025*\"thing\" + 0.024*\"dance\" + 0.023*\"laughter\" + 0.017*\"success\" + 0.015*\"sort\" + 0.015*\"work\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:11,899 : INFO : topic #3 (0.250): 0.027*\"process\" + 0.022*\"work\" + 0.017*\"anybody\" + 0.017*\"laughter\" + 0.017*\"poem\" + 0.017*\"chemical\" + 0.017*\"creativity\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n",
      "2022-05-06 23:31:11,899 : INFO : topic diff=0.009991, rho=0.408248\n",
      "2022-05-06 23:31:11,932 : INFO : -6.261 per-word bound, 76.7 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:11,932 : INFO : PROGRESS: pass 5, at document #175/175\n",
      "2022-05-06 23:31:11,955 : INFO : topic #0 (0.250): 0.042*\"work\" + 0.026*\"way\" + 0.026*\"olé\" + 0.026*\"life\" + 0.026*\"sort\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:11,956 : INFO : topic #1 (0.250): 0.044*\"thing\" + 0.025*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"book\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:11,956 : INFO : topic #2 (0.250): 0.028*\"nt\" + 0.027*\"book\" + 0.026*\"kind\" + 0.024*\"thing\" + 0.024*\"dance\" + 0.023*\"laughter\" + 0.018*\"success\" + 0.015*\"sort\" + 0.015*\"life\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:11,956 : INFO : topic #3 (0.250): 0.028*\"process\" + 0.023*\"work\" + 0.017*\"anybody\" + 0.017*\"laughter\" + 0.017*\"poem\" + 0.017*\"chemical\" + 0.017*\"creativity\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n",
      "2022-05-06 23:31:11,957 : INFO : topic diff=0.007242, rho=0.377964\n",
      "2022-05-06 23:31:11,992 : INFO : -6.259 per-word bound, 76.6 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:11,992 : INFO : PROGRESS: pass 6, at document #175/175\n",
      "2022-05-06 23:31:12,018 : INFO : topic #0 (0.250): 0.043*\"work\" + 0.026*\"way\" + 0.026*\"olé\" + 0.026*\"sort\" + 0.026*\"life\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:12,018 : INFO : topic #1 (0.250): 0.045*\"thing\" + 0.025*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"genius\" + 0.016*\"book\" + 0.016*\"somebody\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:12,019 : INFO : topic #2 (0.250): 0.028*\"book\" + 0.028*\"nt\" + 0.026*\"kind\" + 0.024*\"thing\" + 0.023*\"dance\" + 0.023*\"laughter\" + 0.018*\"success\" + 0.016*\"life\" + 0.015*\"sort\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:12,019 : INFO : topic #3 (0.250): 0.030*\"process\" + 0.023*\"work\" + 0.017*\"anybody\" + 0.017*\"laughter\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"chemical\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:12,020 : INFO : topic diff=0.005981, rho=0.353553\n",
      "2022-05-06 23:31:12,057 : INFO : -6.257 per-word bound, 76.5 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:12,058 : INFO : PROGRESS: pass 7, at document #175/175\n",
      "2022-05-06 23:31:12,080 : INFO : topic #0 (0.250): 0.043*\"work\" + 0.026*\"way\" + 0.026*\"olé\" + 0.026*\"sort\" + 0.026*\"life\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:12,081 : INFO : topic #1 (0.250): 0.045*\"thing\" + 0.025*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"book\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:12,081 : INFO : topic #2 (0.250): 0.029*\"book\" + 0.028*\"nt\" + 0.027*\"kind\" + 0.024*\"thing\" + 0.023*\"dance\" + 0.022*\"laughter\" + 0.018*\"success\" + 0.016*\"life\" + 0.015*\"sort\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:12,082 : INFO : topic #3 (0.250): 0.030*\"process\" + 0.024*\"work\" + 0.019*\"laughter\" + 0.017*\"anybody\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"chemical\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n",
      "2022-05-06 23:31:12,082 : INFO : topic diff=0.004847, rho=0.333333\n",
      "2022-05-06 23:31:12,115 : INFO : -6.255 per-word bound, 76.4 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:12,116 : INFO : PROGRESS: pass 8, at document #175/175\n",
      "2022-05-06 23:31:12,137 : INFO : topic #0 (0.250): 0.043*\"work\" + 0.026*\"way\" + 0.026*\"olé\" + 0.026*\"sort\" + 0.026*\"life\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:12,138 : INFO : topic #1 (0.250): 0.045*\"thing\" + 0.026*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"book\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:12,139 : INFO : topic #2 (0.250): 0.030*\"book\" + 0.029*\"nt\" + 0.027*\"kind\" + 0.024*\"thing\" + 0.023*\"dance\" + 0.021*\"laughter\" + 0.019*\"success\" + 0.017*\"life\" + 0.015*\"sort\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:12,140 : INFO : topic #3 (0.250): 0.031*\"process\" + 0.025*\"work\" + 0.020*\"laughter\" + 0.017*\"anybody\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"chemical\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n",
      "2022-05-06 23:31:12,140 : INFO : topic diff=0.004164, rho=0.316228\n",
      "2022-05-06 23:31:12,173 : INFO : -6.253 per-word bound, 76.3 perplexity estimate based on a held-out corpus of 175 documents with 567 words\n",
      "2022-05-06 23:31:12,174 : INFO : PROGRESS: pass 9, at document #175/175\n",
      "2022-05-06 23:31:12,195 : INFO : topic #0 (0.250): 0.044*\"work\" + 0.026*\"way\" + 0.026*\"olé\" + 0.026*\"sort\" + 0.026*\"life\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:12,195 : INFO : topic #1 (0.250): 0.045*\"thing\" + 0.026*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"book\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:12,196 : INFO : topic #2 (0.250): 0.031*\"book\" + 0.029*\"nt\" + 0.027*\"kind\" + 0.024*\"thing\" + 0.023*\"dance\" + 0.020*\"laughter\" + 0.019*\"success\" + 0.017*\"life\" + 0.015*\"sort\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:12,196 : INFO : topic #3 (0.250): 0.032*\"process\" + 0.026*\"work\" + 0.021*\"laughter\" + 0.017*\"anybody\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"chemical\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n",
      "2022-05-06 23:31:12,196 : INFO : topic diff=0.003906, rho=0.301511\n",
      "2022-05-06 23:31:12,197 : INFO : topic #0 (0.250): 0.044*\"work\" + 0.026*\"way\" + 0.026*\"olé\" + 0.026*\"sort\" + 0.026*\"life\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"\n",
      "2022-05-06 23:31:12,198 : INFO : topic #1 (0.250): 0.045*\"thing\" + 0.026*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"book\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"\n",
      "2022-05-06 23:31:12,198 : INFO : topic #2 (0.250): 0.031*\"book\" + 0.029*\"nt\" + 0.027*\"kind\" + 0.024*\"thing\" + 0.023*\"dance\" + 0.020*\"laughter\" + 0.019*\"success\" + 0.017*\"life\" + 0.015*\"sort\" + 0.015*\"idea\"\n",
      "2022-05-06 23:31:12,199 : INFO : topic #3 (0.250): 0.032*\"process\" + 0.026*\"work\" + 0.021*\"laughter\" + 0.017*\"anybody\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"chemical\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.044*\"work\" + 0.026*\"way\" + 0.026*\"olé\" + 0.026*\"sort\" + 0.026*\"life\" + 0.018*\"kind\" + 0.013*\"artist\" + 0.013*\"allah\" + 0.013*\"divine\" + 0.009*\"genius\"'),\n",
       " (1,\n",
       "  '0.045*\"thing\" + 0.026*\"god\" + 0.021*\"year\" + 0.020*\"sort\" + 0.016*\"genius\" + 0.016*\"somebody\" + 0.016*\"book\" + 0.016*\"allah\" + 0.016*\"applause\" + 0.011*\"mind\"'),\n",
       " (2,\n",
       "  '0.031*\"book\" + 0.029*\"nt\" + 0.027*\"kind\" + 0.024*\"thing\" + 0.023*\"dance\" + 0.020*\"laughter\" + 0.019*\"success\" + 0.017*\"life\" + 0.015*\"sort\" + 0.015*\"idea\"'),\n",
       " (3,\n",
       "  '0.032*\"process\" + 0.026*\"work\" + 0.021*\"laughter\" + 0.017*\"anybody\" + 0.017*\"poem\" + 0.017*\"creativity\" + 0.017*\"chemical\" + 0.017*\"question\" + 0.012*\"idea\" + 0.012*\"engineer\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d643340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "924e6236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book profession s course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great lifelong love fascination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nt s change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>something kind peculiar life career recalibrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>sheer human love stubbornness showing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>applause thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>applause june cohen olé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>applause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript\n",
       "0                                             i writer\n",
       "1                             book profession s course\n",
       "2                      great lifelong love fascination\n",
       "3                                          nt s change\n",
       "4    something kind peculiar life career recalibrat...\n",
       "..                                                 ...\n",
       "170              sheer human love stubbornness showing\n",
       "171                                              thank\n",
       "172                                     applause thank\n",
       "173                            applause june cohen olé\n",
       "174                                           applause\n",
       "\n",
       "[175 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8d43240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>afar</th>\n",
       "      <th>afraid</th>\n",
       "      <th>africa</th>\n",
       "      <th>air</th>\n",
       "      <th>alcoholic</th>\n",
       "      <th>allah</th>\n",
       "      <th>aloud</th>\n",
       "      <th>american</th>\n",
       "      <th>ancient</th>\n",
       "      <th>...</th>\n",
       "      <th>wondrous</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>worst</th>\n",
       "      <th>writer</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  afar  afraid  africa  air  alcoholic  allah  aloud  american  \\\n",
       "0       0     0       0       0    0          0      0      0         0   \n",
       "1       0     0       0       0    0          0      0      0         0   \n",
       "2       0     0       0       0    0          0      0      0         0   \n",
       "3       0     0       0       0    0          0      0      0         0   \n",
       "4       0     0       0       0    0          0      0      0         0   \n",
       "..    ...   ...     ...     ...  ...        ...    ...    ...       ...   \n",
       "170     0     0       0       0    0          0      0      0         0   \n",
       "171     0     0       0       0    0          0      0      0         0   \n",
       "172     0     0       0       0    0          0      0      0         0   \n",
       "173     0     0       0       0    0          0      0      0         0   \n",
       "174     0     0       0       0    0          0      0      0         0   \n",
       "\n",
       "     ancient  ...  wondrous  word  work  world  worried  worst  writer  year  \\\n",
       "0          0  ...         0     0     0      0        0      0       1     0   \n",
       "1          0  ...         0     0     0      0        0      0       0     0   \n",
       "2          0  ...         0     0     0      0        0      0       0     0   \n",
       "3          0  ...         0     0     0      0        0      0       0     0   \n",
       "4          0  ...         0     0     1      0        0      0       0     0   \n",
       "..       ...  ...       ...   ...   ...    ...      ...    ...     ...   ...   \n",
       "170        0  ...         0     0     0      0        0      0       0     0   \n",
       "171        0  ...         0     0     0      0        0      0       0     0   \n",
       "172        0  ...         0     0     0      0        0      0       0     0   \n",
       "173        0  ...         0     0     0      0        0      0       0     0   \n",
       "174        0  ...         0     0     0      0        0      0       0     0   \n",
       "\n",
       "     yes  young  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "..   ...    ...  \n",
       "170    0      0  \n",
       "171    0      0  \n",
       "172    0      0  \n",
       "173    0      0  \n",
       "174    0      0  \n",
       "\n",
       "[175 rows x 441 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bd222f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4daee25f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:12,487 : INFO : using symmetric alpha at 0.2\n",
      "2022-05-06 23:31:12,489 : INFO : using symmetric eta at 0.2\n",
      "2022-05-06 23:31:12,491 : INFO : using serial LDA version on this node\n",
      "2022-05-06 23:31:12,492 : INFO : running online (multi-pass) LDA training, 5 topics, 80 passes over the supplied corpus of 175 documents, updating model once every 175 documents, evaluating perplexity every 175 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-05-06 23:31:12,552 : INFO : -8.841 per-word bound, 458.5 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,553 : INFO : PROGRESS: pass 0, at document #175/175\n",
      "2022-05-06 23:31:12,606 : INFO : topic #0 (0.200): 0.028*\"creative\" + 0.020*\"creativity\" + 0.018*\"sort\" + 0.017*\"human\" + 0.015*\"laughter\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:12,607 : INFO : topic #1 (0.200): 0.017*\"chemical\" + 0.017*\"example\" + 0.017*\"ancient\" + 0.016*\"thing\" + 0.016*\"tom\" + 0.013*\"nt\" + 0.011*\"year\" + 0.011*\"process\" + 0.011*\"afraid\" + 0.011*\"engineer\"\n",
      "2022-05-06 23:31:12,608 : INFO : topic #2 (0.200): 0.027*\"nt\" + 0.025*\"book\" + 0.019*\"work\" + 0.015*\"sort\" + 0.012*\"god\" + 0.011*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.010*\"kind\" + 0.010*\"genius\"\n",
      "2022-05-06 23:31:12,608 : INFO : topic #3 (0.200): 0.027*\"thing\" + 0.019*\"afraid\" + 0.019*\"work\" + 0.018*\"allah\" + 0.016*\"nt\" + 0.011*\"somebody\" + 0.010*\"god\" + 0.010*\"olé\" + 0.010*\"way\" + 0.010*\"pencil\"\n",
      "2022-05-06 23:31:12,608 : INFO : topic #4 (0.200): 0.024*\"kind\" + 0.017*\"life\" + 0.015*\"work\" + 0.014*\"genius\" + 0.012*\"true\" + 0.012*\"question\" + 0.012*\"job\" + 0.012*\"olé\" + 0.012*\"applause\" + 0.010*\"room\"\n",
      "2022-05-06 23:31:12,609 : INFO : topic diff=3.107043, rho=1.000000\n",
      "2022-05-06 23:31:12,646 : INFO : -6.735 per-word bound, 106.5 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,647 : INFO : PROGRESS: pass 1, at document #175/175\n",
      "2022-05-06 23:31:12,669 : INFO : topic #0 (0.200): 0.031*\"creative\" + 0.022*\"laughter\" + 0.020*\"sort\" + 0.019*\"human\" + 0.019*\"creativity\" + 0.015*\"century\" + 0.012*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:12,670 : INFO : topic #1 (0.200): 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"tom\" + 0.014*\"thing\" + 0.012*\"nt\" + 0.012*\"process\" + 0.012*\"year\" + 0.012*\"artist\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:12,670 : INFO : topic #2 (0.200): 0.029*\"nt\" + 0.025*\"book\" + 0.023*\"work\" + 0.019*\"sort\" + 0.015*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"kind\" + 0.011*\"genius\" + 0.010*\"god\"\n",
      "2022-05-06 23:31:12,671 : INFO : topic #3 (0.200): 0.031*\"thing\" + 0.019*\"afraid\" + 0.019*\"allah\" + 0.017*\"work\" + 0.016*\"nt\" + 0.012*\"god\" + 0.012*\"way\" + 0.011*\"somebody\" + 0.010*\"olé\" + 0.010*\"pencil\"\n",
      "2022-05-06 23:31:12,672 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.015*\"question\" + 0.015*\"job\" + 0.013*\"work\" + 0.013*\"genius\" + 0.012*\"true\" + 0.012*\"applause\" + 0.011*\"individual\" + 0.011*\"room\"\n",
      "2022-05-06 23:31:12,673 : INFO : topic diff=0.089331, rho=0.577350\n",
      "2022-05-06 23:31:12,706 : INFO : -6.675 per-word bound, 102.2 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,707 : INFO : PROGRESS: pass 2, at document #175/175\n",
      "2022-05-06 23:31:12,727 : INFO : topic #0 (0.200): 0.033*\"creative\" + 0.025*\"laughter\" + 0.021*\"sort\" + 0.020*\"human\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.011*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:12,728 : INFO : topic #1 (0.200): 0.017*\"ancient\" + 0.017*\"chemical\" + 0.017*\"example\" + 0.017*\"tom\" + 0.014*\"dance\" + 0.013*\"thing\" + 0.012*\"artist\" + 0.012*\"nt\" + 0.012*\"year\" + 0.012*\"process\"\n",
      "2022-05-06 23:31:12,728 : INFO : topic #2 (0.200): 0.030*\"nt\" + 0.026*\"work\" + 0.025*\"book\" + 0.020*\"sort\" + 0.017*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"kind\" + 0.011*\"genius\" + 0.008*\"process\"\n",
      "2022-05-06 23:31:12,729 : INFO : topic #3 (0.200): 0.033*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.015*\"work\" + 0.015*\"nt\" + 0.014*\"god\" + 0.012*\"way\" + 0.010*\"somebody\" + 0.010*\"olé\" + 0.010*\"pencil\"\n",
      "2022-05-06 23:31:12,730 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.016*\"question\" + 0.016*\"job\" + 0.013*\"work\" + 0.012*\"genius\" + 0.012*\"true\" + 0.012*\"applause\" + 0.011*\"individual\" + 0.011*\"room\"\n",
      "2022-05-06 23:31:12,730 : INFO : topic diff=0.049897, rho=0.500000\n",
      "2022-05-06 23:31:12,761 : INFO : -6.654 per-word bound, 100.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,762 : INFO : PROGRESS: pass 3, at document #175/175\n",
      "2022-05-06 23:31:12,783 : INFO : topic #0 (0.200): 0.034*\"creative\" + 0.027*\"laughter\" + 0.021*\"sort\" + 0.020*\"human\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.012*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:12,783 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"ancient\" + 0.017*\"chemical\" + 0.017*\"example\" + 0.016*\"dance\" + 0.014*\"artist\" + 0.013*\"year\" + 0.012*\"thing\" + 0.012*\"nt\" + 0.012*\"process\"\n",
      "2022-05-06 23:31:12,784 : INFO : topic #2 (0.200): 0.031*\"nt\" + 0.029*\"work\" + 0.025*\"book\" + 0.021*\"sort\" + 0.018*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.009*\"process\"\n",
      "2022-05-06 23:31:12,785 : INFO : topic #3 (0.200): 0.034*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.015*\"god\" + 0.015*\"nt\" + 0.013*\"way\" + 0.011*\"work\" + 0.010*\"somebody\" + 0.010*\"olé\" + 0.010*\"pencil\"\n",
      "2022-05-06 23:31:12,785 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.017*\"question\" + 0.017*\"job\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"true\" + 0.012*\"applause\" + 0.012*\"individual\" + 0.012*\"room\"\n",
      "2022-05-06 23:31:12,786 : INFO : topic diff=0.033156, rho=0.447214\n",
      "2022-05-06 23:31:12,817 : INFO : -6.644 per-word bound, 100.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,818 : INFO : PROGRESS: pass 4, at document #175/175\n",
      "2022-05-06 23:31:12,841 : INFO : topic #0 (0.200): 0.034*\"creative\" + 0.027*\"laughter\" + 0.021*\"human\" + 0.020*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:12,841 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"ancient\" + 0.017*\"chemical\" + 0.017*\"example\" + 0.016*\"dance\" + 0.015*\"artist\" + 0.014*\"year\" + 0.012*\"thing\" + 0.012*\"process\" + 0.012*\"nt\"\n",
      "2022-05-06 23:31:12,846 : INFO : topic #2 (0.200): 0.031*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.023*\"sort\" + 0.018*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.009*\"process\"\n",
      "2022-05-06 23:31:12,851 : INFO : topic #3 (0.200): 0.034*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.015*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"somebody\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\"\n",
      "2022-05-06 23:31:12,852 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.017*\"question\" + 0.017*\"job\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"true\" + 0.012*\"applause\" + 0.012*\"individual\" + 0.012*\"room\"\n",
      "2022-05-06 23:31:12,852 : INFO : topic diff=0.021489, rho=0.408248\n",
      "2022-05-06 23:31:12,884 : INFO : -6.639 per-word bound, 99.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,885 : INFO : PROGRESS: pass 5, at document #175/175\n",
      "2022-05-06 23:31:12,905 : INFO : topic #0 (0.200): 0.035*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.019*\"sort\" + 0.018*\"creativity\" + 0.014*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:12,906 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"ancient\" + 0.017*\"chemical\" + 0.017*\"example\" + 0.016*\"dance\" + 0.016*\"artist\" + 0.014*\"year\" + 0.012*\"thing\" + 0.012*\"process\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:12,906 : INFO : topic #2 (0.200): 0.032*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.024*\"sort\" + 0.018*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.009*\"process\"\n",
      "2022-05-06 23:31:12,906 : INFO : topic #3 (0.200): 0.034*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"somebody\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:12,907 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.017*\"question\" + 0.017*\"job\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"true\" + 0.012*\"applause\" + 0.012*\"individual\" + 0.012*\"god\"\n",
      "2022-05-06 23:31:12,907 : INFO : topic diff=0.014211, rho=0.377964\n",
      "2022-05-06 23:31:12,941 : INFO : -6.636 per-word bound, 99.5 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,942 : INFO : PROGRESS: pass 6, at document #175/175\n",
      "2022-05-06 23:31:12,962 : INFO : topic #0 (0.200): 0.035*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.019*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:12,963 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"artist\" + 0.015*\"year\" + 0.012*\"thing\" + 0.012*\"process\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:12,963 : INFO : topic #2 (0.200): 0.033*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.024*\"sort\" + 0.018*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.009*\"process\"\n",
      "2022-05-06 23:31:12,964 : INFO : topic #3 (0.200): 0.034*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"somebody\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\"\n",
      "2022-05-06 23:31:12,965 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.017*\"question\" + 0.017*\"job\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"true\" + 0.012*\"applause\" + 0.012*\"individual\" + 0.012*\"god\"\n",
      "2022-05-06 23:31:12,965 : INFO : topic diff=0.010983, rho=0.353553\n",
      "2022-05-06 23:31:12,996 : INFO : -6.634 per-word bound, 99.3 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:12,997 : INFO : PROGRESS: pass 7, at document #175/175\n",
      "2022-05-06 23:31:13,019 : INFO : topic #0 (0.200): 0.035*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,020 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"artist\" + 0.015*\"year\" + 0.012*\"thing\" + 0.012*\"process\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,021 : INFO : topic #2 (0.200): 0.033*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.010*\"point\"\n",
      "2022-05-06 23:31:13,022 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"somebody\" + 0.010*\"pencil\" + 0.010*\"paper\"\n",
      "2022-05-06 23:31:13,023 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.017*\"question\" + 0.017*\"job\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"true\" + 0.012*\"applause\" + 0.012*\"individual\" + 0.012*\"god\"\n",
      "2022-05-06 23:31:13,024 : INFO : topic diff=0.007613, rho=0.333333\n",
      "2022-05-06 23:31:13,055 : INFO : -6.633 per-word bound, 99.2 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,056 : INFO : PROGRESS: pass 8, at document #175/175\n",
      "2022-05-06 23:31:13,076 : INFO : topic #0 (0.200): 0.035*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,076 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.015*\"year\" + 0.012*\"thing\" + 0.012*\"process\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,077 : INFO : topic #2 (0.200): 0.033*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"kind\" + 0.010*\"point\"\n",
      "2022-05-06 23:31:13,077 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"somebody\" + 0.010*\"pencil\" + 0.010*\"paper\"\n",
      "2022-05-06 23:31:13,078 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"life\" + 0.017*\"question\" + 0.017*\"job\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"individual\" + 0.012*\"true\" + 0.012*\"god\" + 0.012*\"applause\"\n",
      "2022-05-06 23:31:13,078 : INFO : topic diff=0.005369, rho=0.316228\n",
      "2022-05-06 23:31:13,112 : INFO : -6.632 per-word bound, 99.2 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,112 : INFO : PROGRESS: pass 9, at document #175/175\n",
      "2022-05-06 23:31:13,131 : INFO : topic #0 (0.200): 0.036*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,132 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.015*\"year\" + 0.012*\"thing\" + 0.012*\"process\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,133 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"life\" + 0.011*\"kind\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,133 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"somebody\" + 0.010*\"pencil\" + 0.010*\"paper\"\n",
      "2022-05-06 23:31:13,134 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.017*\"life\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"individual\" + 0.012*\"god\" + 0.012*\"idea\" + 0.012*\"true\"\n",
      "2022-05-06 23:31:13,134 : INFO : topic diff=0.003992, rho=0.301511\n",
      "2022-05-06 23:31:13,166 : INFO : -6.631 per-word bound, 99.1 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,166 : INFO : PROGRESS: pass 10, at document #175/175\n",
      "2022-05-06 23:31:13,186 : INFO : topic #0 (0.200): 0.037*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,186 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.015*\"year\" + 0.012*\"thing\" + 0.012*\"process\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,187 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,188 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"somebody\" + 0.010*\"pencil\" + 0.010*\"paper\"\n",
      "2022-05-06 23:31:13,189 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.017*\"life\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"individual\" + 0.012*\"god\" + 0.012*\"idea\" + 0.012*\"true\"\n",
      "2022-05-06 23:31:13,189 : INFO : topic diff=0.003067, rho=0.288675\n",
      "2022-05-06 23:31:13,221 : INFO : -6.630 per-word bound, 99.1 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,221 : INFO : PROGRESS: pass 11, at document #175/175\n",
      "2022-05-06 23:31:13,241 : INFO : topic #0 (0.200): 0.037*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,242 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"thing\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,243 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,243 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"somebody\"\n",
      "2022-05-06 23:31:13,244 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.017*\"life\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"true\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:13,244 : INFO : topic diff=0.002372, rho=0.277350\n",
      "2022-05-06 23:31:13,275 : INFO : -6.630 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,276 : INFO : PROGRESS: pass 12, at document #175/175\n",
      "2022-05-06 23:31:13,296 : INFO : topic #0 (0.200): 0.037*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,296 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"thing\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,297 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,297 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"rational\"\n",
      "2022-05-06 23:31:13,298 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.017*\"life\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"true\"\n",
      "2022-05-06 23:31:13,298 : INFO : topic diff=0.001851, rho=0.267261\n",
      "2022-05-06 23:31:13,330 : INFO : -6.630 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,331 : INFO : PROGRESS: pass 13, at document #175/175\n",
      "2022-05-06 23:31:13,350 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.011*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,351 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"thing\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,351 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,352 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"rational\"\n",
      "2022-05-06 23:31:13,353 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.017*\"life\" + 0.012*\"idea\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,353 : INFO : topic diff=0.001456, rho=0.258199\n",
      "2022-05-06 23:31:13,384 : INFO : -6.630 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,384 : INFO : PROGRESS: pass 14, at document #175/175\n",
      "2022-05-06 23:31:13,403 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,404 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"thing\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,404 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,405 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"rational\"\n",
      "2022-05-06 23:31:13,405 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.017*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"work\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,406 : INFO : topic diff=0.001157, rho=0.250000\n",
      "2022-05-06 23:31:13,440 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,440 : INFO : PROGRESS: pass 15, at document #175/175\n",
      "2022-05-06 23:31:13,462 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"reputation\" + 0.011*\"spirit\"\n",
      "2022-05-06 23:31:13,463 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"thing\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,464 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,464 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"rational\"\n",
      "2022-05-06 23:31:13,464 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,465 : INFO : topic diff=0.000928, rho=0.242536\n",
      "2022-05-06 23:31:13,497 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,497 : INFO : PROGRESS: pass 16, at document #175/175\n",
      "2022-05-06 23:31:13,518 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,518 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"thing\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,519 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,520 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"rational\"\n",
      "2022-05-06 23:31:13,520 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,521 : INFO : topic diff=0.000750, rho=0.235702\n",
      "2022-05-06 23:31:13,551 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,552 : INFO : PROGRESS: pass 17, at document #175/175\n",
      "2022-05-06 23:31:13,571 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,572 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"thing\" + 0.012*\"success\"\n",
      "2022-05-06 23:31:13,573 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,573 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,574 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"work\" + 0.012*\"genius\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,575 : INFO : topic diff=0.000611, rho=0.229416\n",
      "2022-05-06 23:31:13,607 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:13,607 : INFO : PROGRESS: pass 18, at document #175/175\n",
      "2022-05-06 23:31:13,628 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,629 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"artist\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"thing\"\n",
      "2022-05-06 23:31:13,629 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,630 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,631 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,631 : INFO : topic diff=0.000500, rho=0.223607\n",
      "2022-05-06 23:31:13,662 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,663 : INFO : PROGRESS: pass 19, at document #175/175\n",
      "2022-05-06 23:31:13,684 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.015*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,684 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"thing\"\n",
      "2022-05-06 23:31:13,685 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,686 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,686 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,687 : INFO : topic diff=0.000412, rho=0.218218\n",
      "2022-05-06 23:31:13,718 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,718 : INFO : PROGRESS: pass 20, at document #175/175\n",
      "2022-05-06 23:31:13,738 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,739 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:13,739 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,740 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,741 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,741 : INFO : topic diff=0.000776, rho=0.213201\n",
      "2022-05-06 23:31:13,772 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,772 : INFO : PROGRESS: pass 21, at document #175/175\n",
      "2022-05-06 23:31:13,793 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,794 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:13,795 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,795 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,796 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,797 : INFO : topic diff=0.000889, rho=0.208514\n",
      "2022-05-06 23:31:13,832 : INFO : -6.629 per-word bound, 99.0 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,832 : INFO : PROGRESS: pass 22, at document #175/175\n",
      "2022-05-06 23:31:13,852 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,853 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:13,854 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,855 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.019*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,855 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,856 : INFO : topic diff=0.000707, rho=0.204124\n",
      "2022-05-06 23:31:13,887 : INFO : -6.629 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,888 : INFO : PROGRESS: pass 23, at document #175/175\n",
      "2022-05-06 23:31:13,910 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"sort\" + 0.018*\"creativity\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:13,911 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:13,912 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,912 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,913 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,913 : INFO : topic diff=0.000565, rho=0.200000\n",
      "2022-05-06 23:31:13,945 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:13,946 : INFO : PROGRESS: pass 24, at document #175/175\n",
      "2022-05-06 23:31:13,965 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:13,966 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:13,967 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:13,967 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:13,968 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:13,969 : INFO : topic diff=0.000456, rho=0.196116\n",
      "2022-05-06 23:31:14,000 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,000 : INFO : PROGRESS: pass 25, at document #175/175\n",
      "2022-05-06 23:31:14,021 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,021 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,022 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,022 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,023 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,023 : INFO : topic diff=0.000371, rho=0.192450\n",
      "2022-05-06 23:31:14,056 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,057 : INFO : PROGRESS: pass 26, at document #175/175\n",
      "2022-05-06 23:31:14,076 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,077 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,078 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,078 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,079 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,080 : INFO : topic diff=0.000303, rho=0.188982\n",
      "2022-05-06 23:31:14,111 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,111 : INFO : PROGRESS: pass 27, at document #175/175\n",
      "2022-05-06 23:31:14,133 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,133 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,133 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,134 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,134 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,135 : INFO : topic diff=0.000249, rho=0.185695\n",
      "2022-05-06 23:31:14,166 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,167 : INFO : PROGRESS: pass 28, at document #175/175\n",
      "2022-05-06 23:31:14,189 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,190 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,190 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,191 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,191 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,192 : INFO : topic diff=0.000206, rho=0.182574\n",
      "2022-05-06 23:31:14,222 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,223 : INFO : PROGRESS: pass 29, at document #175/175\n",
      "2022-05-06 23:31:14,243 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,243 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,244 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,244 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,245 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,245 : INFO : topic diff=0.000172, rho=0.179605\n",
      "2022-05-06 23:31:14,278 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,279 : INFO : PROGRESS: pass 30, at document #175/175\n",
      "2022-05-06 23:31:14,302 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,302 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:14,303 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,303 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,304 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,305 : INFO : topic diff=0.000146, rho=0.176777\n",
      "2022-05-06 23:31:14,335 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,336 : INFO : PROGRESS: pass 31, at document #175/175\n",
      "2022-05-06 23:31:14,356 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,357 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"example\" + 0.017*\"artist\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,357 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,358 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,358 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,358 : INFO : topic diff=0.000124, rho=0.174078\n",
      "2022-05-06 23:31:14,391 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,392 : INFO : PROGRESS: pass 32, at document #175/175\n",
      "2022-05-06 23:31:14,412 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,413 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,413 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,414 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,414 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,414 : INFO : topic diff=0.000107, rho=0.171499\n",
      "2022-05-06 23:31:14,446 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,447 : INFO : PROGRESS: pass 33, at document #175/175\n",
      "2022-05-06 23:31:14,467 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,468 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,468 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,468 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,469 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,469 : INFO : topic diff=0.000094, rho=0.169031\n",
      "2022-05-06 23:31:14,502 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,502 : INFO : PROGRESS: pass 34, at document #175/175\n",
      "2022-05-06 23:31:14,522 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"reputation\"\n",
      "2022-05-06 23:31:14,523 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,523 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,524 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,525 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,525 : INFO : topic diff=0.000084, rho=0.166667\n",
      "2022-05-06 23:31:14,557 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,558 : INFO : PROGRESS: pass 35, at document #175/175\n",
      "2022-05-06 23:31:14,577 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,578 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,578 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,579 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,580 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,580 : INFO : topic diff=0.000076, rho=0.164399\n",
      "2022-05-06 23:31:14,611 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,612 : INFO : PROGRESS: pass 36, at document #175/175\n",
      "2022-05-06 23:31:14,632 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,633 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,633 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:14,634 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,635 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,635 : INFO : topic diff=0.000070, rho=0.162221\n",
      "2022-05-06 23:31:14,666 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,667 : INFO : PROGRESS: pass 37, at document #175/175\n",
      "2022-05-06 23:31:14,688 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,689 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,690 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,690 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,691 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,691 : INFO : topic diff=0.000066, rho=0.160128\n",
      "2022-05-06 23:31:14,730 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,730 : INFO : PROGRESS: pass 38, at document #175/175\n",
      "2022-05-06 23:31:14,750 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,750 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,751 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,751 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,751 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,752 : INFO : topic diff=0.000064, rho=0.158114\n",
      "2022-05-06 23:31:14,783 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,784 : INFO : PROGRESS: pass 39, at document #175/175\n",
      "2022-05-06 23:31:14,806 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,806 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,807 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,807 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,808 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,808 : INFO : topic diff=0.000063, rho=0.156174\n",
      "2022-05-06 23:31:14,840 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,840 : INFO : PROGRESS: pass 40, at document #175/175\n",
      "2022-05-06 23:31:14,859 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,860 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,861 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,861 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,862 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,862 : INFO : topic diff=0.000065, rho=0.154303\n",
      "2022-05-06 23:31:14,893 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,894 : INFO : PROGRESS: pass 41, at document #175/175\n",
      "2022-05-06 23:31:14,913 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,914 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,915 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,915 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:14,916 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,916 : INFO : topic diff=0.000068, rho=0.152499\n",
      "2022-05-06 23:31:14,948 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:14,948 : INFO : PROGRESS: pass 42, at document #175/175\n",
      "2022-05-06 23:31:14,967 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:14,968 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:14,969 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:14,970 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:14,970 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:14,971 : INFO : topic diff=0.000074, rho=0.150756\n",
      "2022-05-06 23:31:15,001 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,002 : INFO : PROGRESS: pass 43, at document #175/175\n",
      "2022-05-06 23:31:15,023 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,024 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,024 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,025 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,026 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,026 : INFO : topic diff=0.000084, rho=0.149071\n",
      "2022-05-06 23:31:15,058 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,059 : INFO : PROGRESS: pass 44, at document #175/175\n",
      "2022-05-06 23:31:15,080 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,080 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,081 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,082 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,082 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,083 : INFO : topic diff=0.000099, rho=0.147442\n",
      "2022-05-06 23:31:15,113 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,114 : INFO : PROGRESS: pass 45, at document #175/175\n",
      "2022-05-06 23:31:15,133 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,134 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,134 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,135 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,136 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,137 : INFO : topic diff=0.000124, rho=0.145865\n",
      "2022-05-06 23:31:15,168 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,169 : INFO : PROGRESS: pass 46, at document #175/175\n",
      "2022-05-06 23:31:15,190 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,191 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,192 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,192 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,193 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,193 : INFO : topic diff=0.000170, rho=0.144338\n",
      "2022-05-06 23:31:15,225 : INFO : -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,225 : INFO : PROGRESS: pass 47, at document #175/175\n",
      "2022-05-06 23:31:15,245 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,246 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,247 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,247 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,248 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,248 : INFO : topic diff=0.000325, rho=0.142857\n",
      "2022-05-06 23:31:15,278 : INFO : -6.627 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,279 : INFO : PROGRESS: pass 48, at document #175/175\n",
      "2022-05-06 23:31:15,298 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,299 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,300 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,300 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,301 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:15,302 : INFO : topic diff=0.000603, rho=0.141421\n",
      "2022-05-06 23:31:15,332 : INFO : -6.627 per-word bound, 98.8 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,333 : INFO : PROGRESS: pass 49, at document #175/175\n",
      "2022-05-06 23:31:15,353 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,354 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.016*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,354 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,355 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,355 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,356 : INFO : topic diff=0.000463, rho=0.140028\n",
      "2022-05-06 23:31:15,387 : INFO : -6.626 per-word bound, 98.8 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,388 : INFO : PROGRESS: pass 50, at document #175/175\n",
      "2022-05-06 23:31:15,407 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,408 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,408 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,409 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,409 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,410 : INFO : topic diff=0.000380, rho=0.138675\n",
      "2022-05-06 23:31:15,441 : INFO : -6.626 per-word bound, 98.8 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,442 : INFO : PROGRESS: pass 51, at document #175/175\n",
      "2022-05-06 23:31:15,462 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,463 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,464 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,464 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,465 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,465 : INFO : topic diff=0.000324, rho=0.137361\n",
      "2022-05-06 23:31:15,496 : INFO : -6.626 per-word bound, 98.8 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,497 : INFO : PROGRESS: pass 52, at document #175/175\n",
      "2022-05-06 23:31:15,516 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"unknowable\"\n",
      "2022-05-06 23:31:15,517 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,517 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,518 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,519 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,519 : INFO : topic diff=0.000283, rho=0.136083\n",
      "2022-05-06 23:31:15,550 : INFO : -6.626 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,551 : INFO : PROGRESS: pass 53, at document #175/175\n",
      "2022-05-06 23:31:15,572 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"source\"\n",
      "2022-05-06 23:31:15,573 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,573 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,574 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,574 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,575 : INFO : topic diff=0.000252, rho=0.134840\n",
      "2022-05-06 23:31:15,606 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,606 : INFO : PROGRESS: pass 54, at document #175/175\n",
      "2022-05-06 23:31:15,625 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"divine\" + 0.011*\"source\"\n",
      "2022-05-06 23:31:15,626 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,627 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,627 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,628 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,629 : INFO : topic diff=0.000226, rho=0.133631\n",
      "2022-05-06 23:31:15,676 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:15,677 : INFO : PROGRESS: pass 55, at document #175/175\n",
      "2022-05-06 23:31:15,699 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:15,699 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,700 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,701 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,701 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,701 : INFO : topic diff=0.000205, rho=0.132453\n",
      "2022-05-06 23:31:15,735 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,736 : INFO : PROGRESS: pass 56, at document #175/175\n",
      "2022-05-06 23:31:15,758 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:15,759 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,760 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,760 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,761 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,762 : INFO : topic diff=0.000187, rho=0.131306\n",
      "2022-05-06 23:31:15,793 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,794 : INFO : PROGRESS: pass 57, at document #175/175\n",
      "2022-05-06 23:31:15,817 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:15,817 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,818 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,819 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,819 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,820 : INFO : topic diff=0.000171, rho=0.130189\n",
      "2022-05-06 23:31:15,854 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,854 : INFO : PROGRESS: pass 58, at document #175/175\n",
      "2022-05-06 23:31:15,876 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:15,876 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,876 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,877 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,877 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,878 : INFO : topic diff=0.000157, rho=0.129099\n",
      "2022-05-06 23:31:15,911 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,911 : INFO : PROGRESS: pass 59, at document #175/175\n",
      "2022-05-06 23:31:15,934 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:15,935 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,935 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,936 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,937 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,937 : INFO : topic diff=0.000144, rho=0.128037\n",
      "2022-05-06 23:31:15,975 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:15,975 : INFO : PROGRESS: pass 60, at document #175/175\n",
      "2022-05-06 23:31:15,995 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:15,996 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:15,996 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:15,997 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:15,998 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:15,998 : INFO : topic diff=0.000132, rho=0.127000\n",
      "2022-05-06 23:31:16,032 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,033 : INFO : PROGRESS: pass 61, at document #175/175\n",
      "2022-05-06 23:31:16,054 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:16,054 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,055 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,056 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,057 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,058 : INFO : topic diff=0.000122, rho=0.125988\n",
      "2022-05-06 23:31:16,091 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,092 : INFO : PROGRESS: pass 62, at document #175/175\n",
      "2022-05-06 23:31:16,111 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,112 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.017*\"year\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,113 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,113 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,114 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,114 : INFO : topic diff=0.000111, rho=0.125000\n",
      "2022-05-06 23:31:16,148 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,148 : INFO : PROGRESS: pass 63, at document #175/175\n",
      "2022-05-06 23:31:16,168 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,169 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"year\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,170 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,171 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,171 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,172 : INFO : topic diff=0.000102, rho=0.124035\n",
      "2022-05-06 23:31:16,206 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,207 : INFO : PROGRESS: pass 64, at document #175/175\n",
      "2022-05-06 23:31:16,229 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,229 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"year\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,230 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,230 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,231 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,231 : INFO : topic diff=0.000093, rho=0.123091\n",
      "2022-05-06 23:31:16,266 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,267 : INFO : PROGRESS: pass 65, at document #175/175\n",
      "2022-05-06 23:31:16,288 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,289 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"year\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,289 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,290 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,291 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,292 : INFO : topic diff=0.000085, rho=0.122169\n",
      "2022-05-06 23:31:16,323 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,324 : INFO : PROGRESS: pass 66, at document #175/175\n",
      "2022-05-06 23:31:16,346 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,346 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"chemical\" + 0.017*\"year\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,347 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,347 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,348 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,349 : INFO : topic diff=0.000077, rho=0.121268\n",
      "2022-05-06 23:31:16,386 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,387 : INFO : PROGRESS: pass 67, at document #175/175\n",
      "2022-05-06 23:31:16,407 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,407 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:16,408 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,408 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,408 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,409 : INFO : topic diff=0.000070, rho=0.120386\n",
      "2022-05-06 23:31:16,442 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,443 : INFO : PROGRESS: pass 68, at document #175/175\n",
      "2022-05-06 23:31:16,463 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,464 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,464 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,464 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,465 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,466 : INFO : topic diff=0.000063, rho=0.119523\n",
      "2022-05-06 23:31:16,497 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,498 : INFO : PROGRESS: pass 69, at document #175/175\n",
      "2022-05-06 23:31:16,518 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,519 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,520 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,521 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,521 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,522 : INFO : topic diff=0.000057, rho=0.118678\n",
      "2022-05-06 23:31:16,553 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,553 : INFO : PROGRESS: pass 70, at document #175/175\n",
      "2022-05-06 23:31:16,574 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,574 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,575 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,576 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,576 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,577 : INFO : topic diff=0.000051, rho=0.117851\n",
      "2022-05-06 23:31:16,608 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,608 : INFO : PROGRESS: pass 71, at document #175/175\n",
      "2022-05-06 23:31:16,628 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,628 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,629 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,629 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,630 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,630 : INFO : topic diff=0.000046, rho=0.117041\n",
      "2022-05-06 23:31:16,662 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,663 : INFO : PROGRESS: pass 72, at document #175/175\n",
      "2022-05-06 23:31:16,683 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,683 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,684 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,685 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,686 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,687 : INFO : topic diff=0.000041, rho=0.116248\n",
      "2022-05-06 23:31:16,721 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,721 : INFO : PROGRESS: pass 73, at document #175/175\n",
      "2022-05-06 23:31:16,741 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,742 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,743 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,743 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:16,744 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,744 : INFO : topic diff=0.000037, rho=0.115470\n",
      "2022-05-06 23:31:16,776 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,777 : INFO : PROGRESS: pass 74, at document #175/175\n",
      "2022-05-06 23:31:16,797 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,797 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,798 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,799 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,800 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,800 : INFO : topic diff=0.000033, rho=0.114708\n",
      "2022-05-06 23:31:16,833 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,833 : INFO : PROGRESS: pass 75, at document #175/175\n",
      "2022-05-06 23:31:16,854 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,855 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,855 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,856 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"pencil\" + 0.010*\"paper\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,857 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,857 : INFO : topic diff=0.000030, rho=0.113961\n",
      "2022-05-06 23:31:16,889 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,890 : INFO : PROGRESS: pass 76, at document #175/175\n",
      "2022-05-06 23:31:16,909 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,910 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,911 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,911 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,912 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,912 : INFO : topic diff=0.000027, rho=0.113228\n",
      "2022-05-06 23:31:16,945 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:16,946 : INFO : PROGRESS: pass 77, at document #175/175\n",
      "2022-05-06 23:31:16,966 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:16,966 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:16,967 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:16,967 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:16,968 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:16,969 : INFO : topic diff=0.000024, rho=0.112509\n",
      "2022-05-06 23:31:17,000 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:17,000 : INFO : PROGRESS: pass 78, at document #175/175\n",
      "2022-05-06 23:31:17,020 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:17,021 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:17,022 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:17,022 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:17,023 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:17,024 : INFO : topic diff=0.000021, rho=0.111803\n",
      "2022-05-06 23:31:17,069 : INFO : -6.625 per-word bound, 98.7 perplexity estimate based on a held-out corpus of 175 documents with 825 words\n",
      "2022-05-06 23:31:17,070 : INFO : PROGRESS: pass 79, at document #175/175\n",
      "2022-05-06 23:31:17,096 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:17,099 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:17,100 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:17,101 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:17,101 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n",
      "2022-05-06 23:31:17,102 : INFO : topic diff=0.000019, rho=0.111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 23:31:17,103 : INFO : topic #0 (0.200): 0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"\n",
      "2022-05-06 23:31:17,103 : INFO : topic #1 (0.200): 0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"\n",
      "2022-05-06 23:31:17,104 : INFO : topic #2 (0.200): 0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"\n",
      "2022-05-06 23:31:17,105 : INFO : topic #3 (0.200): 0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"\n",
      "2022-05-06 23:31:17,106 : INFO : topic #4 (0.200): 0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.038*\"creative\" + 0.028*\"laughter\" + 0.021*\"human\" + 0.018*\"creativity\" + 0.018*\"sort\" + 0.014*\"century\" + 0.013*\"work\" + 0.012*\"life\" + 0.011*\"source\" + 0.011*\"divine\"'),\n",
       " (1,\n",
       "  '0.017*\"tom\" + 0.017*\"year\" + 0.017*\"chemical\" + 0.017*\"ancient\" + 0.017*\"artist\" + 0.017*\"example\" + 0.017*\"dance\" + 0.012*\"process\" + 0.012*\"success\" + 0.012*\"genius\"'),\n",
       " (2,\n",
       "  '0.034*\"work\" + 0.031*\"nt\" + 0.025*\"book\" + 0.025*\"sort\" + 0.018*\"olé\" + 0.011*\"genius\" + 0.011*\"kind\" + 0.011*\"life\" + 0.011*\"moment\" + 0.011*\"point\"'),\n",
       " (3,\n",
       "  '0.035*\"thing\" + 0.020*\"allah\" + 0.019*\"afraid\" + 0.016*\"god\" + 0.014*\"nt\" + 0.013*\"way\" + 0.010*\"olé\" + 0.010*\"paper\" + 0.010*\"pencil\" + 0.010*\"feel\"'),\n",
       " (4,\n",
       "  '0.023*\"kind\" + 0.017*\"question\" + 0.017*\"job\" + 0.016*\"life\" + 0.012*\"idea\" + 0.012*\"god\" + 0.012*\"individual\" + 0.012*\"genius\" + 0.012*\"work\" + 0.012*\"big\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=5, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bec4a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(0, 0.10001757),\n",
       "   (1, 0.100025475),\n",
       "   (2, 0.10266737),\n",
       "   (3, 0.10001644),\n",
       "   (4, 0.5972732)],\n",
       "  0),\n",
       " ([(0, 0.050008),\n",
       "   (1, 0.050011504),\n",
       "   (2, 0.7997865),\n",
       "   (3, 0.050182223),\n",
       "   (4, 0.050011728)],\n",
       "  1),\n",
       " ([(0, 0.041195203),\n",
       "   (1, 0.040014274),\n",
       "   (2, 0.040325277),\n",
       "   (3, 0.83795357),\n",
       "   (4, 0.040511653)],\n",
       "  2),\n",
       " ([(0, 0.06667127),\n",
       "   (1, 0.7269902),\n",
       "   (2, 0.07145717),\n",
       "   (3, 0.06820793),\n",
       "   (4, 0.06667343)],\n",
       "  3),\n",
       " ([(0, 0.025269017),\n",
       "   (1, 0.02502202),\n",
       "   (2, 0.025569938),\n",
       "   (3, 0.025201015),\n",
       "   (4, 0.89893806)],\n",
       "  4),\n",
       " ([(0, 0.012525681),\n",
       "   (1, 0.01251511),\n",
       "   (2, 0.012757372),\n",
       "   (3, 0.94957083),\n",
       "   (4, 0.012630969)],\n",
       "  5),\n",
       " ([(0, 0.10001293),\n",
       "   (1, 0.10001875),\n",
       "   (2, 0.100013204),\n",
       "   (3, 0.599936),\n",
       "   (4, 0.10001912)],\n",
       "  6),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 7),\n",
       " ([(0, 0.040005766),\n",
       "   (1, 0.040360942),\n",
       "   (2, 0.040855214),\n",
       "   (3, 0.8387696),\n",
       "   (4, 0.04000844)],\n",
       "  8),\n",
       " ([(0, 0.022302562),\n",
       "   (1, 0.022629883),\n",
       "   (2, 0.9101332),\n",
       "   (3, 0.022603476),\n",
       "   (4, 0.022330897)],\n",
       "  9),\n",
       " ([(0, 0.10001781),\n",
       "   (1, 0.599921),\n",
       "   (2, 0.10001818),\n",
       "   (3, 0.10001666),\n",
       "   (4, 0.10002633)],\n",
       "  10),\n",
       " ([(0, 0.03364962),\n",
       "   (1, 0.034637462),\n",
       "   (2, 0.8643568),\n",
       "   (3, 0.03373138),\n",
       "   (4, 0.03362475)],\n",
       "  11),\n",
       " ([(0, 0.050003294),\n",
       "   (1, 0.79513574),\n",
       "   (2, 0.052830916),\n",
       "   (3, 0.052025177),\n",
       "   (4, 0.050004832)],\n",
       "  12),\n",
       " ([(0, 0.033338767),\n",
       "   (1, 0.03357058),\n",
       "   (2, 0.033894565),\n",
       "   (3, 0.8658548),\n",
       "   (4, 0.03334128)],\n",
       "  13),\n",
       " ([(0, 0.014328194),\n",
       "   (1, 0.01433487),\n",
       "   (2, 0.9426123),\n",
       "   (3, 0.0143863475),\n",
       "   (4, 0.014338302)],\n",
       "  14),\n",
       " ([(0, 0.599987),\n",
       "   (1, 0.10000386),\n",
       "   (2, 0.10000274),\n",
       "   (3, 0.10000249),\n",
       "   (4, 0.100003935)],\n",
       "  15),\n",
       " ([(0, 0.03333711),\n",
       "   (1, 0.8656813),\n",
       "   (2, 0.033337187),\n",
       "   (3, 0.03355472),\n",
       "   (4, 0.034089666)],\n",
       "  16),\n",
       " ([(0, 0.050005104),\n",
       "   (1, 0.0513627),\n",
       "   (2, 0.050246034),\n",
       "   (3, 0.79837865),\n",
       "   (4, 0.050007485)],\n",
       "  17),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 18),\n",
       " ([(0, 0.028575227),\n",
       "   (1, 0.028716952),\n",
       "   (2, 0.028651811),\n",
       "   (3, 0.88547903),\n",
       "   (4, 0.02857698)],\n",
       "  19),\n",
       " ([(0, 0.06820375),\n",
       "   (1, 0.06771004),\n",
       "   (2, 0.43389842),\n",
       "   (3, 0.3635163),\n",
       "   (4, 0.06667147)],\n",
       "  20),\n",
       " ([(0, 0.100008205),\n",
       "   (1, 0.10001189),\n",
       "   (2, 0.100008376),\n",
       "   (3, 0.59995943),\n",
       "   (4, 0.10001213)],\n",
       "  21),\n",
       " ([(0, 0.028843272),\n",
       "   (1, 0.029198157),\n",
       "   (2, 0.029787716),\n",
       "   (3, 0.88336873),\n",
       "   (4, 0.028802099)],\n",
       "  22),\n",
       " ([(0, 0.021622194),\n",
       "   (1, 0.020277156),\n",
       "   (2, 0.020514345),\n",
       "   (3, 0.9168382),\n",
       "   (4, 0.020748127)],\n",
       "  23),\n",
       " ([(0, 0.015428331),\n",
       "   (1, 0.93828565),\n",
       "   (2, 0.0154275065),\n",
       "   (3, 0.015472295),\n",
       "   (4, 0.015386246)],\n",
       "  24),\n",
       " ([(0, 0.06668422),\n",
       "   (1, 0.06669201),\n",
       "   (2, 0.066684596),\n",
       "   (3, 0.7332467),\n",
       "   (4, 0.0666925)],\n",
       "  25),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 26),\n",
       " ([(0, 0.91931325),\n",
       "   (1, 0.0206634),\n",
       "   (2, 0.020003758),\n",
       "   (3, 0.020014219),\n",
       "   (4, 0.020005373)],\n",
       "  27),\n",
       " ([(0, 0.8984137),\n",
       "   (1, 0.02516393),\n",
       "   (2, 0.025382407),\n",
       "   (3, 0.025096025),\n",
       "   (4, 0.025943931)],\n",
       "  28),\n",
       " ([(0, 0.9197155),\n",
       "   (1, 0.02001077),\n",
       "   (2, 0.020063391),\n",
       "   (3, 0.020205654),\n",
       "   (4, 0.020004703)],\n",
       "  29),\n",
       " ([(0, 0.033339337),\n",
       "   (1, 0.0333968),\n",
       "   (2, 0.86650497),\n",
       "   (3, 0.033416778),\n",
       "   (4, 0.033342116)],\n",
       "  30),\n",
       " ([(0, 0.03333938),\n",
       "   (1, 0.033622567),\n",
       "   (2, 0.86587244),\n",
       "   (3, 0.033823468),\n",
       "   (4, 0.033342175)],\n",
       "  31),\n",
       " ([(0, 0.83769846),\n",
       "   (1, 0.040006317),\n",
       "   (2, 0.041322377),\n",
       "   (3, 0.040320802),\n",
       "   (4, 0.04065202)],\n",
       "  32),\n",
       " ([(0, 0.014496291),\n",
       "   (1, 0.0143503435),\n",
       "   (2, 0.014319656),\n",
       "   (3, 0.01444165),\n",
       "   (4, 0.94239205)],\n",
       "  33),\n",
       " ([(0, 0.028801976),\n",
       "   (1, 0.02879864),\n",
       "   (2, 0.028721014),\n",
       "   (3, 0.8835972),\n",
       "   (4, 0.030081179)],\n",
       "  34),\n",
       " ([(0, 0.100011624),\n",
       "   (1, 0.100016855),\n",
       "   (2, 0.5999434),\n",
       "   (3, 0.10001087),\n",
       "   (4, 0.10001719)],\n",
       "  35),\n",
       " ([(0, 0.050494246),\n",
       "   (1, 0.050013274),\n",
       "   (2, 0.7994703),\n",
       "   (3, 0.05000865),\n",
       "   (4, 0.050013535)],\n",
       "  36),\n",
       " ([(0, 0.10002982),\n",
       "   (1, 0.10004328),\n",
       "   (2, 0.10003045),\n",
       "   (3, 0.5998523),\n",
       "   (4, 0.100044146)],\n",
       "  37),\n",
       " ([(0, 0.73310226),\n",
       "   (1, 0.06668069),\n",
       "   (2, 0.066676594),\n",
       "   (3, 0.06685948),\n",
       "   (4, 0.06668097)],\n",
       "  38),\n",
       " ([(0, 0.8853278),\n",
       "   (1, 0.028797684),\n",
       "   (2, 0.028575549),\n",
       "   (3, 0.028633835),\n",
       "   (4, 0.028665144)],\n",
       "  39),\n",
       " ([(0, 0.91059965),\n",
       "   (1, 0.022245627),\n",
       "   (2, 0.022515217),\n",
       "   (3, 0.02229377),\n",
       "   (4, 0.022345793)],\n",
       "  40),\n",
       " ([(0, 0.04045557),\n",
       "   (1, 0.04084954),\n",
       "   (2, 0.040138576),\n",
       "   (3, 0.83854586),\n",
       "   (4, 0.04001042)],\n",
       "  41),\n",
       " ([(0, 0.067023024),\n",
       "   (1, 0.066678986),\n",
       "   (2, 0.7324896),\n",
       "   (3, 0.06683977),\n",
       "   (4, 0.06696864)],\n",
       "  42),\n",
       " ([(0, 0.02503525),\n",
       "   (1, 0.02553279),\n",
       "   (2, 0.8991287),\n",
       "   (3, 0.02527158),\n",
       "   (4, 0.025031686)],\n",
       "  43),\n",
       " ([(0, 0.034169402),\n",
       "   (1, 0.86416113),\n",
       "   (2, 0.034946114),\n",
       "   (3, 0.033383645),\n",
       "   (4, 0.033339683)],\n",
       "  44),\n",
       " ([(0, 0.06667694),\n",
       "   (1, 0.066681474),\n",
       "   (2, 0.06735148),\n",
       "   (3, 0.06667628),\n",
       "   (4, 0.73261386)],\n",
       "  45),\n",
       " ([(0, 0.0223175),\n",
       "   (1, 0.022279926),\n",
       "   (2, 0.910509),\n",
       "   (3, 0.022373024),\n",
       "   (4, 0.022520596)],\n",
       "  46),\n",
       " ([(0, 0.72798955),\n",
       "   (1, 0.066670515),\n",
       "   (2, 0.07062837),\n",
       "   (3, 0.06716317),\n",
       "   (4, 0.067548394)],\n",
       "  47),\n",
       " ([(0, 0.1000048),\n",
       "   (1, 0.100997314),\n",
       "   (2, 0.1000049),\n",
       "   (3, 0.1005586),\n",
       "   (4, 0.5984344)],\n",
       "  48),\n",
       " ([(0, 0.91916394),\n",
       "   (1, 0.020057159),\n",
       "   (2, 0.020312117),\n",
       "   (3, 0.020274261),\n",
       "   (4, 0.02019251)],\n",
       "  49),\n",
       " ([(0, 0.025297098),\n",
       "   (1, 0.025164329),\n",
       "   (2, 0.89853287),\n",
       "   (3, 0.025850711),\n",
       "   (4, 0.025154985)],\n",
       "  50),\n",
       " ([(0, 0.9380091),\n",
       "   (1, 0.015603191),\n",
       "   (2, 0.015471126),\n",
       "   (3, 0.015486379),\n",
       "   (4, 0.0154301785)],\n",
       "  51),\n",
       " ([(0, 0.033850092),\n",
       "   (1, 0.86613804),\n",
       "   (2, 0.03333688),\n",
       "   (3, 0.033336587),\n",
       "   (4, 0.0333384)],\n",
       "  52),\n",
       " ([(0, 0.06668245),\n",
       "   (1, 0.066689454),\n",
       "   (2, 0.7332567),\n",
       "   (3, 0.06668145),\n",
       "   (4, 0.06668991)],\n",
       "  53),\n",
       " ([(0, 0.8992343),\n",
       "   (1, 0.025699947),\n",
       "   (2, 0.025002675),\n",
       "   (3, 0.025016006),\n",
       "   (4, 0.025047058)],\n",
       "  54),\n",
       " ([(0, 0.9332135),\n",
       "   (1, 0.016668566),\n",
       "   (2, 0.01669372),\n",
       "   (3, 0.016720377),\n",
       "   (4, 0.016703859)],\n",
       "  55),\n",
       " ([(0, 0.88536775),\n",
       "   (1, 0.028576242),\n",
       "   (2, 0.028799357),\n",
       "   (3, 0.02859278),\n",
       "   (4, 0.028663905)],\n",
       "  56),\n",
       " ([(0, 0.033519458),\n",
       "   (1, 0.03334387),\n",
       "   (2, 0.8664524),\n",
       "   (3, 0.03334022),\n",
       "   (4, 0.03334407)],\n",
       "  57),\n",
       " ([(0, 0.8832522),\n",
       "   (1, 0.029120857),\n",
       "   (2, 0.029325593),\n",
       "   (3, 0.028778657),\n",
       "   (4, 0.029522685)],\n",
       "  58),\n",
       " ([(0, 0.033789493),\n",
       "   (1, 0.03351801),\n",
       "   (2, 0.033525374),\n",
       "   (3, 0.033535093),\n",
       "   (4, 0.865632)],\n",
       "  59),\n",
       " ([(0, 0.01120013),\n",
       "   (1, 0.01123091),\n",
       "   (2, 0.9552389),\n",
       "   (3, 0.011141629),\n",
       "   (4, 0.011188396)],\n",
       "  60),\n",
       " ([(0, 0.02543546),\n",
       "   (1, 0.025007278),\n",
       "   (2, 0.026221568),\n",
       "   (3, 0.8981614),\n",
       "   (4, 0.025174255)],\n",
       "  61),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 62),\n",
       " ([(0, 0.028679777),\n",
       "   (1, 0.8849797),\n",
       "   (2, 0.0286712),\n",
       "   (3, 0.029094577),\n",
       "   (4, 0.028574731)],\n",
       "  63),\n",
       " ([(0, 0.028652672),\n",
       "   (1, 0.028700119),\n",
       "   (2, 0.8851073),\n",
       "   (3, 0.028798593),\n",
       "   (4, 0.028741283)],\n",
       "  64),\n",
       " ([(0, 0.06701571),\n",
       "   (1, 0.06667254),\n",
       "   (2, 0.7325139),\n",
       "   (3, 0.06683543),\n",
       "   (4, 0.066962436)],\n",
       "  65),\n",
       " ([(0, 0.05019112),\n",
       "   (1, 0.05058384),\n",
       "   (2, 0.050763395),\n",
       "   (3, 0.050176524),\n",
       "   (4, 0.7982851)],\n",
       "  66),\n",
       " ([(0, 0.839389),\n",
       "   (1, 0.040007416),\n",
       "   (2, 0.040005274),\n",
       "   (3, 0.040044118),\n",
       "   (4, 0.0405542)],\n",
       "  67),\n",
       " ([(0, 0.0119985),\n",
       "   (1, 0.011766463),\n",
       "   (2, 0.011799951),\n",
       "   (3, 0.0118342),\n",
       "   (4, 0.9526009)],\n",
       "  68),\n",
       " ([(0, 0.03491261),\n",
       "   (1, 0.033343397),\n",
       "   (2, 0.03334049),\n",
       "   (3, 0.8638208),\n",
       "   (4, 0.034582756)],\n",
       "  69),\n",
       " ([(0, 0.03359184),\n",
       "   (1, 0.8650966),\n",
       "   (2, 0.033823438),\n",
       "   (3, 0.033540078),\n",
       "   (4, 0.033948053)],\n",
       "  70),\n",
       " ([(0, 0.06667693),\n",
       "   (1, 0.06668147),\n",
       "   (2, 0.066677146),\n",
       "   (3, 0.06667628),\n",
       "   (4, 0.7332882)],\n",
       "  71),\n",
       " ([(0, 0.955403),\n",
       "   (1, 0.011115442),\n",
       "   (2, 0.011141341),\n",
       "   (3, 0.011176447),\n",
       "   (4, 0.011163797)],\n",
       "  72),\n",
       " ([(0, 0.050150365),\n",
       "   (1, 0.0500138),\n",
       "   (2, 0.05000979),\n",
       "   (3, 0.7995819),\n",
       "   (4, 0.0502442)],\n",
       "  73),\n",
       " ([(0, 0.033339847),\n",
       "   (1, 0.033342693),\n",
       "   (2, 0.86663514),\n",
       "   (3, 0.033339445),\n",
       "   (4, 0.033342864)],\n",
       "  74),\n",
       " ([(0, 0.050171226),\n",
       "   (1, 0.7993481),\n",
       "   (2, 0.05029223),\n",
       "   (3, 0.05018264),\n",
       "   (4, 0.05000578)],\n",
       "  75),\n",
       " ([(0, 0.050002817),\n",
       "   (1, 0.05013019),\n",
       "   (2, 0.050002877),\n",
       "   (3, 0.05007696),\n",
       "   (4, 0.79978716)],\n",
       "  76),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 77),\n",
       " ([(0, 0.60755616),\n",
       "   (1, 0.028919991),\n",
       "   (2, 0.30531895),\n",
       "   (3, 0.028591689),\n",
       "   (4, 0.029613215)],\n",
       "  78),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 79),\n",
       " ([(0, 0.028636571),\n",
       "   (1, 0.028957356),\n",
       "   (2, 0.028637659),\n",
       "   (3, 0.885189),\n",
       "   (4, 0.0285794)],\n",
       "  80),\n",
       " ([(0, 0.016669832),\n",
       "   (1, 0.016671196),\n",
       "   (2, 0.016669897),\n",
       "   (3, 0.93317723),\n",
       "   (4, 0.01681183)],\n",
       "  81),\n",
       " ([(0, 0.5998656),\n",
       "   (1, 0.1000399),\n",
       "   (2, 0.10002808),\n",
       "   (3, 0.10002573),\n",
       "   (4, 0.1000407)],\n",
       "  82),\n",
       " ([(0, 0.050062153),\n",
       "   (1, 0.05023149),\n",
       "   (2, 0.05023358),\n",
       "   (3, 0.050133277),\n",
       "   (4, 0.79933953)],\n",
       "  83),\n",
       " ([(0, 0.101912744),\n",
       "   (1, 0.10118847),\n",
       "   (2, 0.1007875),\n",
       "   (3, 0.5948617),\n",
       "   (4, 0.1012496)],\n",
       "  84),\n",
       " ([(0, 0.030289415),\n",
       "   (1, 0.88376534),\n",
       "   (2, 0.028684791),\n",
       "   (3, 0.028683485),\n",
       "   (4, 0.028576981)],\n",
       "  85),\n",
       " ([(0, 0.05022219),\n",
       "   (1, 0.798938),\n",
       "   (2, 0.05058419),\n",
       "   (3, 0.05024879),\n",
       "   (4, 0.050006896)],\n",
       "  86),\n",
       " ([(0, 0.7332768),\n",
       "   (1, 0.06668341),\n",
       "   (2, 0.06667852),\n",
       "   (3, 0.06667754),\n",
       "   (4, 0.06668374)],\n",
       "  87),\n",
       " ([(0, 0.94628865),\n",
       "   (1, 0.013374798),\n",
       "   (2, 0.013455436),\n",
       "   (3, 0.013428796),\n",
       "   (4, 0.013452293)],\n",
       "  88),\n",
       " ([(0, 0.050012648),\n",
       "   (1, 0.0500182),\n",
       "   (2, 0.05058196),\n",
       "   (3, 0.7993687),\n",
       "   (4, 0.050018553)],\n",
       "  89),\n",
       " ([(0, 0.7328088),\n",
       "   (1, 0.06668342),\n",
       "   (2, 0.06714644),\n",
       "   (3, 0.06667755),\n",
       "   (4, 0.06668375)],\n",
       "  90),\n",
       " ([(0, 0.066679254),\n",
       "   (1, 0.06668483),\n",
       "   (2, 0.06667952),\n",
       "   (3, 0.7332712),\n",
       "   (4, 0.066685185)],\n",
       "  91),\n",
       " ([(0, 0.04000788),\n",
       "   (1, 0.040173378),\n",
       "   (2, 0.2475142),\n",
       "   (3, 0.43265358),\n",
       "   (4, 0.23965095)],\n",
       "  92),\n",
       " ([(0, 0.020029752),\n",
       "   (1, 0.020102462),\n",
       "   (2, 0.02024203),\n",
       "   (3, 0.91947496),\n",
       "   (4, 0.020150812)],\n",
       "  93),\n",
       " ([(0, 0.041766558),\n",
       "   (1, 0.040009208),\n",
       "   (2, 0.8374988),\n",
       "   (3, 0.040530235),\n",
       "   (4, 0.040195227)],\n",
       "  94),\n",
       " ([(0, 0.066676766),\n",
       "   (1, 0.06668122),\n",
       "   (2, 0.73081076),\n",
       "   (3, 0.06914978),\n",
       "   (4, 0.06668151)],\n",
       "  95),\n",
       " ([(0, 0.025092587),\n",
       "   (1, 0.025004068),\n",
       "   (2, 0.02523327),\n",
       "   (3, 0.89959544),\n",
       "   (4, 0.02507465)],\n",
       "  96),\n",
       " ([(0, 0.033416104),\n",
       "   (1, 0.03334269),\n",
       "   (2, 0.8654368),\n",
       "   (3, 0.03367741),\n",
       "   (4, 0.034126982)],\n",
       "  97),\n",
       " ([(0, 0.02506314),\n",
       "   (1, 0.025004651),\n",
       "   (2, 0.025283389),\n",
       "   (3, 0.02519101),\n",
       "   (4, 0.89945775)],\n",
       "  98),\n",
       " ([(0, 0.8385892),\n",
       "   (1, 0.040688444),\n",
       "   (2, 0.040540814),\n",
       "   (3, 0.04017558),\n",
       "   (4, 0.040005956)],\n",
       "  99),\n",
       " ([(0, 0.5432803),\n",
       "   (1, 0.040627763),\n",
       "   (2, 0.33591402),\n",
       "   (3, 0.040165193),\n",
       "   (4, 0.0400127)],\n",
       "  100),\n",
       " ([(0, 0.028929103),\n",
       "   (1, 0.028830672),\n",
       "   (2, 0.029157436),\n",
       "   (3, 0.029051902),\n",
       "   (4, 0.8840309)],\n",
       "  101),\n",
       " ([(0, 0.10000212),\n",
       "   (1, 0.10103062),\n",
       "   (2, 0.10031989),\n",
       "   (3, 0.59864426),\n",
       "   (4, 0.10000315)],\n",
       "  102),\n",
       " ([(0, 0.10255936),\n",
       "   (1, 0.100025475),\n",
       "   (2, 0.10001794),\n",
       "   (3, 0.10001644),\n",
       "   (4, 0.5973808)],\n",
       "  103),\n",
       " ([(0, 0.7313561),\n",
       "   (1, 0.0666731),\n",
       "   (2, 0.06667122),\n",
       "   (3, 0.06754575),\n",
       "   (4, 0.06775389)],\n",
       "  104),\n",
       " ([(0, 0.10000212),\n",
       "   (1, 0.10102943),\n",
       "   (2, 0.10031998),\n",
       "   (3, 0.5986453),\n",
       "   (4, 0.10000315)],\n",
       "  105),\n",
       " ([(0, 0.865753),\n",
       "   (1, 0.033458173),\n",
       "   (2, 0.03341753),\n",
       "   (3, 0.033907168),\n",
       "   (4, 0.03346414)],\n",
       "  106),\n",
       " ([(0, 0.01823273),\n",
       "   (1, 0.927147),\n",
       "   (2, 0.01823386),\n",
       "   (3, 0.018201645),\n",
       "   (4, 0.018184789)],\n",
       "  107),\n",
       " ([(0, 0.9421733),\n",
       "   (1, 0.014740146),\n",
       "   (2, 0.014462402),\n",
       "   (3, 0.014296323),\n",
       "   (4, 0.014327802)],\n",
       "  108),\n",
       " ([(0, 0.033338215),\n",
       "   (1, 0.8664571),\n",
       "   (2, 0.033338316),\n",
       "   (3, 0.033337913),\n",
       "   (4, 0.033528406)],\n",
       "  109),\n",
       " ([(0, 0.01544113),\n",
       "   (1, 0.015400195),\n",
       "   (2, 0.015411382),\n",
       "   (3, 0.9383465),\n",
       "   (4, 0.015400816)],\n",
       "  110),\n",
       " ([(0, 0.040006325),\n",
       "   (1, 0.040009085),\n",
       "   (2, 0.040006455),\n",
       "   (3, 0.83996886),\n",
       "   (4, 0.040009264)],\n",
       "  111),\n",
       " ([(0, 0.020066785),\n",
       "   (1, 0.020020666),\n",
       "   (2, 0.020194681),\n",
       "   (3, 0.919713),\n",
       "   (4, 0.02000484)],\n",
       "  112),\n",
       " ([(0, 0.100029826),\n",
       "   (1, 0.10004328),\n",
       "   (2, 0.10003046),\n",
       "   (3, 0.5998523),\n",
       "   (4, 0.10004414)],\n",
       "  113),\n",
       " ([(0, 0.5998656),\n",
       "   (1, 0.1000399),\n",
       "   (2, 0.10002808),\n",
       "   (3, 0.10002573),\n",
       "   (4, 0.1000407)],\n",
       "  114),\n",
       " ([(0, 0.05026582),\n",
       "   (1, 0.05059358),\n",
       "   (2, 0.7985214),\n",
       "   (3, 0.050606184),\n",
       "   (4, 0.050013002)],\n",
       "  115),\n",
       " ([(0, 0.5998656),\n",
       "   (1, 0.100039914),\n",
       "   (2, 0.10002809),\n",
       "   (3, 0.100025736),\n",
       "   (4, 0.1000407)],\n",
       "  116),\n",
       " ([(0, 0.599987),\n",
       "   (1, 0.10000386),\n",
       "   (2, 0.10000274),\n",
       "   (3, 0.10000249),\n",
       "   (4, 0.100003935)],\n",
       "  117),\n",
       " ([(0, 0.04000604),\n",
       "   (1, 0.04000868),\n",
       "   (2, 0.83997077),\n",
       "   (3, 0.040005665),\n",
       "   (4, 0.040008843)],\n",
       "  118),\n",
       " ([(0, 0.06697072),\n",
       "   (1, 0.06667566),\n",
       "   (2, 0.06667304),\n",
       "   (3, 0.73165596),\n",
       "   (4, 0.06802465)],\n",
       "  119),\n",
       " ([(0, 0.10000756),\n",
       "   (1, 0.10001096),\n",
       "   (2, 0.10000772),\n",
       "   (3, 0.10000707),\n",
       "   (4, 0.5999667)],\n",
       "  120),\n",
       " ([(0, 0.06759772),\n",
       "   (1, 0.06798262),\n",
       "   (2, 0.73031574),\n",
       "   (3, 0.067144185),\n",
       "   (4, 0.06695969)],\n",
       "  121),\n",
       " ([(0, 0.42856383),\n",
       "   (1, 0.05000674),\n",
       "   (2, 0.42068997),\n",
       "   (3, 0.050268065),\n",
       "   (4, 0.050471395)],\n",
       "  122),\n",
       " ([(0, 0.022444014),\n",
       "   (1, 0.022912633),\n",
       "   (2, 0.022906622),\n",
       "   (3, 0.90919954),\n",
       "   (4, 0.022537114)],\n",
       "  123),\n",
       " ([(0, 0.018231254),\n",
       "   (1, 0.92658883),\n",
       "   (2, 0.018337125),\n",
       "   (3, 0.018398548),\n",
       "   (4, 0.018444274)],\n",
       "  124),\n",
       " ([(0, 0.033760924),\n",
       "   (1, 0.03339832),\n",
       "   (2, 0.0334653),\n",
       "   (3, 0.86564386),\n",
       "   (4, 0.033731606)],\n",
       "  125),\n",
       " ([(0, 0.015442993),\n",
       "   (1, 0.015393674),\n",
       "   (2, 0.9382688),\n",
       "   (3, 0.01550627),\n",
       "   (4, 0.015388264)],\n",
       "  126),\n",
       " ([(0, 0.05000586),\n",
       "   (1, 0.05077044),\n",
       "   (2, 0.7990376),\n",
       "   (3, 0.050177533),\n",
       "   (4, 0.050008595)],\n",
       "  127),\n",
       " ([(0, 0.10001293),\n",
       "   (1, 0.10001875),\n",
       "   (2, 0.100013204),\n",
       "   (3, 0.599936),\n",
       "   (4, 0.10001912)],\n",
       "  128),\n",
       " ([(0, 0.050490092),\n",
       "   (1, 0.05399181),\n",
       "   (2, 0.795053),\n",
       "   (3, 0.050448265),\n",
       "   (4, 0.0500168)],\n",
       "  129),\n",
       " ([(0, 0.028575107),\n",
       "   (1, 0.028576707),\n",
       "   (2, 0.028575184),\n",
       "   (3, 0.028574882),\n",
       "   (4, 0.88569814)],\n",
       "  130),\n",
       " ([(0, 0.025003042),\n",
       "   (1, 0.025327861),\n",
       "   (2, 0.89810836),\n",
       "   (3, 0.026556293),\n",
       "   (4, 0.025004448)],\n",
       "  131),\n",
       " ([(0, 0.100002386),\n",
       "   (1, 0.101105504),\n",
       "   (2, 0.5972466),\n",
       "   (3, 0.10164196),\n",
       "   (4, 0.10000353)],\n",
       "  132),\n",
       " ([(0, 0.040185597),\n",
       "   (1, 0.8391546),\n",
       "   (2, 0.04018933),\n",
       "   (3, 0.04017107),\n",
       "   (4, 0.04029943)],\n",
       "  133),\n",
       " ([(0, 0.10000821),\n",
       "   (1, 0.10001191),\n",
       "   (2, 0.10000857),\n",
       "   (3, 0.5999588),\n",
       "   (4, 0.100012556)],\n",
       "  134),\n",
       " ([(0, 0.10000479),\n",
       "   (1, 0.100953095),\n",
       "   (2, 0.1000049),\n",
       "   (3, 0.10000449),\n",
       "   (4, 0.59903276)],\n",
       "  135),\n",
       " ([(0, 0.040004745),\n",
       "   (1, 0.040080007),\n",
       "   (2, 0.040004842),\n",
       "   (3, 0.04039568),\n",
       "   (4, 0.8395147)],\n",
       "  136),\n",
       " ([(0, 0.9497914),\n",
       "   (1, 0.012611756),\n",
       "   (2, 0.012501847),\n",
       "   (3, 0.012522904),\n",
       "   (4, 0.012572145)],\n",
       "  137),\n",
       " ([(0, 0.05000922),\n",
       "   (1, 0.050013263),\n",
       "   (2, 0.79976875),\n",
       "   (3, 0.050195243),\n",
       "   (4, 0.050013524)],\n",
       "  138),\n",
       " ([(0, 0.06667717),\n",
       "   (1, 0.73259586),\n",
       "   (2, 0.06736834),\n",
       "   (3, 0.06667651),\n",
       "   (4, 0.066682115)],\n",
       "  139),\n",
       " ([(0, 0.04030223),\n",
       "   (1, 0.040437866),\n",
       "   (2, 0.838239),\n",
       "   (3, 0.040070858),\n",
       "   (4, 0.040950015)],\n",
       "  140),\n",
       " ([(0, 0.025028626),\n",
       "   (1, 0.025073571),\n",
       "   (2, 0.89957756),\n",
       "   (3, 0.02510567),\n",
       "   (4, 0.025214598)],\n",
       "  141),\n",
       " ([(0, 0.7320996),\n",
       "   (1, 0.066679895),\n",
       "   (2, 0.06667604),\n",
       "   (3, 0.06765973),\n",
       "   (4, 0.06688475)],\n",
       "  142),\n",
       " ([(0, 0.050004702),\n",
       "   (1, 0.79997915),\n",
       "   (2, 0.050004803),\n",
       "   (3, 0.050004408),\n",
       "   (4, 0.050006896)],\n",
       "  143),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 144),\n",
       " ([(0, 0.02225808),\n",
       "   (1, 0.022224428),\n",
       "   (2, 0.022338176),\n",
       "   (3, 0.91067296),\n",
       "   (4, 0.022506345)],\n",
       "  145),\n",
       " ([(0, 0.10000475),\n",
       "   (1, 0.100006886),\n",
       "   (2, 0.10061655),\n",
       "   (3, 0.59692514),\n",
       "   (4, 0.10244667)],\n",
       "  146),\n",
       " ([(0, 0.010131339),\n",
       "   (1, 0.010112774),\n",
       "   (2, 0.010117545),\n",
       "   (3, 0.95959306),\n",
       "   (4, 0.0100453105)],\n",
       "  147),\n",
       " ([(0, 0.014315917),\n",
       "   (1, 0.014332148),\n",
       "   (2, 0.9421388),\n",
       "   (3, 0.014804603),\n",
       "   (4, 0.01440858)],\n",
       "  148),\n",
       " ([(0, 0.7321635),\n",
       "   (1, 0.06668343),\n",
       "   (2, 0.06667853),\n",
       "   (3, 0.067076564),\n",
       "   (4, 0.06739803)],\n",
       "  149),\n",
       " ([(0, 0.01818556),\n",
       "   (1, 0.018187173),\n",
       "   (2, 0.018440634),\n",
       "   (3, 0.9269694),\n",
       "   (4, 0.018217213)],\n",
       "  150),\n",
       " ([(0, 0.033338215),\n",
       "   (1, 0.8665224),\n",
       "   (2, 0.033461057),\n",
       "   (3, 0.033337913),\n",
       "   (4, 0.03334047)],\n",
       "  151),\n",
       " ([(0, 0.03347281),\n",
       "   (1, 0.03333845),\n",
       "   (2, 0.03351798),\n",
       "   (3, 0.03379296),\n",
       "   (4, 0.86587775)],\n",
       "  152),\n",
       " ([(0, 0.5998656),\n",
       "   (1, 0.10003991),\n",
       "   (2, 0.10002808),\n",
       "   (3, 0.10002573),\n",
       "   (4, 0.1000407)],\n",
       "  153),\n",
       " ([(0, 0.28480384),\n",
       "   (1, 0.0401202),\n",
       "   (2, 0.040234417),\n",
       "   (3, 0.040126886),\n",
       "   (4, 0.59471464)],\n",
       "  154),\n",
       " ([(0, 0.033837497),\n",
       "   (1, 0.033472363),\n",
       "   (2, 0.033795357),\n",
       "   (3, 0.8652285),\n",
       "   (4, 0.033666313)],\n",
       "  155),\n",
       " ([(0, 0.026020171),\n",
       "   (1, 0.02500779),\n",
       "   (2, 0.025420409),\n",
       "   (3, 0.8978743),\n",
       "   (4, 0.025677338)],\n",
       "  156),\n",
       " ([(0, 0.068355136),\n",
       "   (1, 0.7256431),\n",
       "   (2, 0.06736131),\n",
       "   (3, 0.07086369),\n",
       "   (4, 0.06777676)],\n",
       "  157),\n",
       " ([(0, 0.033339404),\n",
       "   (1, 0.034120798),\n",
       "   (2, 0.03441198),\n",
       "   (3, 0.8647856),\n",
       "   (4, 0.033342212)],\n",
       "  158),\n",
       " ([(0, 0.04043154),\n",
       "   (1, 0.040478766),\n",
       "   (2, 0.43914184),\n",
       "   (3, 0.439938),\n",
       "   (4, 0.040009804)],\n",
       "  159),\n",
       " ([(0, 0.100002386),\n",
       "   (1, 0.1010875),\n",
       "   (2, 0.5973291),\n",
       "   (3, 0.101577505),\n",
       "   (4, 0.100003526)],\n",
       "  160),\n",
       " ([(0, 0.10000479),\n",
       "   (1, 0.100957915),\n",
       "   (2, 0.1000049),\n",
       "   (3, 0.10000449),\n",
       "   (4, 0.59902793)],\n",
       "  161),\n",
       " ([(0, 0.100012936),\n",
       "   (1, 0.100018755),\n",
       "   (2, 0.10180737),\n",
       "   (3, 0.5981418),\n",
       "   (4, 0.10001913)],\n",
       "  162),\n",
       " ([(0, 0.050404526),\n",
       "   (1, 0.7971755),\n",
       "   (2, 0.050003998),\n",
       "   (3, 0.05015924),\n",
       "   (4, 0.052256707)],\n",
       "  163),\n",
       " ([(0, 0.025285115),\n",
       "   (1, 0.02509595),\n",
       "   (2, 0.8993544),\n",
       "   (3, 0.025076024),\n",
       "   (4, 0.02518853)],\n",
       "  164),\n",
       " ([(0, 0.10158151),\n",
       "   (1, 0.59782946),\n",
       "   (2, 0.10000504),\n",
       "   (3, 0.10057669),\n",
       "   (4, 0.10000729)],\n",
       "  165),\n",
       " ([(0, 0.10000426),\n",
       "   (1, 0.100006185),\n",
       "   (2, 0.5971444),\n",
       "   (3, 0.1019855),\n",
       "   (4, 0.10085958)],\n",
       "  166),\n",
       " ([(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)], 167),\n",
       " ([(0, 0.10000821),\n",
       "   (1, 0.1000119),\n",
       "   (2, 0.10000838),\n",
       "   (3, 0.5999594),\n",
       "   (4, 0.10001214)],\n",
       "  168),\n",
       " ([(0, 0.10000426),\n",
       "   (1, 0.100006185),\n",
       "   (2, 0.59716),\n",
       "   (3, 0.10197042),\n",
       "   (4, 0.100859165)],\n",
       "  169),\n",
       " ([(0, 0.8662436),\n",
       "   (1, 0.03334226),\n",
       "   (2, 0.033527836),\n",
       "   (3, 0.033506867),\n",
       "   (4, 0.033379458)],\n",
       "  170),\n",
       " ([(0, 0.59994173),\n",
       "   (1, 0.100017294),\n",
       "   (2, 0.100012176),\n",
       "   (3, 0.100011155),\n",
       "   (4, 0.10001764)],\n",
       "  171),\n",
       " ([(0, 0.73148906),\n",
       "   (1, 0.066676825),\n",
       "   (2, 0.06667386),\n",
       "   (3, 0.066673264),\n",
       "   (4, 0.06848703)],\n",
       "  172),\n",
       " ([(0, 0.040180672),\n",
       "   (1, 0.040005982),\n",
       "   (2, 0.04133531),\n",
       "   (3, 0.04063122),\n",
       "   (4, 0.8378469)],\n",
       "  173),\n",
       " ([(0, 0.10245352),\n",
       "   (1, 0.100010976),\n",
       "   (2, 0.100007735),\n",
       "   (3, 0.10000709),\n",
       "   (4, 0.59752065)],\n",
       "  174)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for a in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "137cda88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Dom_Topic  Topic_Contri  \\\n",
      "0          4.0        0.5974   \n",
      "1          2.0        0.7998   \n",
      "2          3.0        0.8380   \n",
      "3          1.0        0.7272   \n",
      "4          4.0        0.8989   \n",
      "..         ...           ...   \n",
      "170        0.0        0.8662   \n",
      "171        0.0        0.5999   \n",
      "172        0.0        0.7315   \n",
      "173        4.0        0.8378   \n",
      "174        4.0        0.5974   \n",
      "\n",
      "                                                                             Keywords  \n",
      "0                 kind, question, job, life, idea, god, individual, genius, work, big  \n",
      "1                        work, nt, book, sort, olé, genius, kind, life, moment, point  \n",
      "2                        thing, allah, afraid, god, nt, way, olé, paper, pencil, feel  \n",
      "3      tom, year, chemical, ancient, artist, example, dance, process, success, genius  \n",
      "4                 kind, question, job, life, idea, god, individual, genius, work, big  \n",
      "..                                                                                ...  \n",
      "170  creative, laughter, human, creativity, sort, century, work, life, source, divine  \n",
      "171  creative, laughter, human, creativity, sort, century, work, life, source, divine  \n",
      "172  creative, laughter, human, creativity, sort, century, work, life, source, divine  \n",
      "173               kind, question, job, life, idea, god, individual, genius, work, big  \n",
      "174               kind, question, job, life, idea, god, individual, genius, work, big  \n",
      "\n",
      "[175 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sent_topics_df = pd.DataFrame()\n",
    "for i, row_list in enumerate(ldana[corpusna]):\n",
    "        row = row_list[0] if ldana.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldana.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "sent_topics_df.columns = ['Dom_Topic', 'Topic_Contri', 'Keywords']\n",
    "print(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd582911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {}\n",
    "# sentences = \"\"\n",
    "# corpus = pd.read_pickle(\"corpus.pkl\")\n",
    "# corpus\n",
    "# i=0\n",
    "# a=0\n",
    "# z=0\n",
    "# x=0\n",
    "# while(a<len(sent_topics_df)-1):\n",
    "#     sentences = corpus.loc[a].at['transcript']\n",
    "#     if(sent_topics_df.loc[a].at[\"Dom_Topic\"] == sent_topics_df.loc[a+1].at[\"Dom_Topic\"]):\n",
    "#         while((a<len(sent_topics_df)-1) and (sent_topics_df.loc[a].at[\"Dom_Topic\"] == sent_topics_df.loc[a+1].at[\"Dom_Topic\"])):\n",
    "#             sentences += corpus.loc[a+1].at['transcript']\n",
    "#             a+=1\n",
    "#     data[i] = sentences\n",
    "#     i+=1\n",
    "#     a+=1\n",
    "# if(a<len(sent_topics_df)):\n",
    "#     data[i] = sentences = corpus.loc[a].at['transcript']\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35006106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {}\n",
    "# sentences = \"\"\n",
    "# corpus = pd.read_pickle(\"corpus.pkl\")\n",
    "# corpus\n",
    "# i=0\n",
    "# a=0\n",
    "# z=0\n",
    "# x=0\n",
    "# y=1\n",
    "# j=1\n",
    "# time_and_sentences = pd.read_pickle('time_and_sentences.pkl')\n",
    "# keys = list(time_and_sentences.keys())\n",
    "# values = list(time_and_sentences.values())\n",
    "\n",
    "# while(a<len(sent_topics_df)-1):\n",
    "#     sentences = corpus.loc[a].at['transcript']\n",
    "#     if(sent_topics_df.loc[a].at[\"Dom_Topic\"] == sent_topics_df.loc[a+1].at[\"Dom_Topic\"]):\n",
    "#         while((a<len(sent_topics_df)-1) and (sent_topics_df.loc[a].at[\"Dom_Topic\"] == sent_topics_df.loc[a+1].at[\"Dom_Topic\"])):\n",
    "#             sentences += corpus.loc[a+1].at['transcript']\n",
    "#             if(y < len(values) and (values[y]-j) >= (a+1)):\n",
    "#                 values[y] = values[y]-j\n",
    "#                 y += 1\n",
    "                \n",
    "#             else:\n",
    "#                 while(y < len(values) and (values[y]-j) < (a+1)):\n",
    "#                     values[y] = values[y]-j\n",
    "#                     y += 1\n",
    "                    \n",
    "#             j += 1\n",
    "#             a+=1\n",
    "#     data[i] = sentences\n",
    "#     i+=1\n",
    "#     a+=1\n",
    "# if(a<len(sent_topics_df)):\n",
    "#     data[i] = sentences = corpus.loc[a].at['transcript']\n",
    "\n",
    "# values.sort()\n",
    "\n",
    "# time_and_sentences = dict(zip(keys, values))\n",
    "# pickle.dump(time_and_sentences, open(\"time_and_sentences.pkl\", \"wb\" ))\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a776a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' i writer ',\n",
       " 1: 'writing book profession s  course ',\n",
       " 2: 'it also great lifelong love fascination ',\n",
       " 3: 'and i nt expect s ever going change ',\n",
       " 4: 'but  said  something kind peculiar happened recently life career  caused recalibrate whole relationship work ',\n",
       " 5: 'and peculiar thing i recently wrote book  memoir called  eat  pray  love   decidedly unlike previous book  went world reason  became big  megasensation  international bestseller thing the result everywhere i go  people treat like i m doomed ',\n",
       " 6: 'seriously  doomed  doomed ',\n",
       " 7: 'like  come  worried  say   are nt afraid re never going able top ',\n",
       " 8: 'are nt afraid re going keep writing whole life re never going create book anybody world care  ever  ',\n",
       " 9: ' so s reassuring  know ',\n",
       " 10: 'but would worse  except i happen remember  year ago  i teenager  i first started telling people i wanted writer  i met sort fearbased reaction ',\n",
       " 11: 'and people would say   are nt afraid re never going success ',\n",
       " 12: 'are nt afraid humiliation rejection kill ',\n",
       " 13: 'are nt afraid re going work whole life craft nothing s ever going come re going die scrap heap broken dream mouth filled bitter ash failure  ',\n",
       " 14: '  laughter   like  know ',\n",
       " 15: ' the answer  short answer question   yes  ',\n",
       " 16: 'yes  i m afraid thing ',\n",
       " 17: 'and i always ',\n",
       " 18: 'and i m afraid many  many thing besides people ca nt even guess  like seaweed thing scary ',\n",
       " 19: 'but  come writing  thing i ve sort thinking lately  wondering lately  ',\n",
       " 20: 'you know  rational is logical anybody expected afraid work feel put earth and specifically creative venture seems make u really nervous s mental health way career kind nt  know ',\n",
       " 21: 'like dad  example  chemical engineer i nt recall  year chemical engineering anybody asking afraid chemical engineer  know ',\n",
       " 22: ' that chemicalengineering block  john  s going  ',\n",
       " 23: 'it nt come like  know but fair  chemical engineer group nt really earned reputation century alcoholic manicdepressive   laughter   we writer  kind reputation  writer  creative people across genre  seems  reputation enormously mentally unstable and look grim death count  century alone  really magnificent creative mind died young often hand  know ',\n",
       " 24: 'and even one nt literally commit suicide seem really undone gift  know norman mailer  died  last interview  said   every one book killed little  ',\n",
       " 25: 'an extraordinary statement make life s work ',\n",
       " 26: 'but nt even blink hear somebody say  ve heard kind stuff long somehow ve completely internalized accepted collectively notion creativity suffering somehow inherently linked artistry  end  always ultimately lead anguish ',\n",
       " 27: ' and question i want ask everybody today guy cool idea ',\n",
       " 28: 'are comfortable because look even inch away  know  i m comfortable assumption ',\n",
       " 29: 'i think s odious ',\n",
       " 30: 'and i also think s dangerous  i nt want see perpetuated next century i think s better encourage great creative mind live  and i definitely know  case  situation  would dangerous start sort leaking dark path assumption  particularly given circumstance i m right career ',\n",
       " 31: 'which  know  like check  i m pretty young  i m  year old ',\n",
       " 32: 'i still maybe another four decade work left and s exceedingly likely anything i write point forward going judged world work came freakish success last book  right ',\n",
       " 33: 'i put bluntly  re sort friend  s exceedingly likely greatest success behind ',\n",
       " 34: 'so jesus  thought ',\n",
       " 35: 'that s kind thought could lead person start drinking gin nine oclock morning  i nt want go ',\n",
       " 36: '  laughter   i would prefer keep work i love ',\n",
       " 37: ' and  question becomes  ',\n",
       " 38: 'and  seems  upon lot reflection  way i work  order continue writing  i create sort protective psychological construct  right ',\n",
       " 39: 'i sort find way safe distance  i writing  natural anxiety reaction writing going  ',\n",
       " 40: 'and  i ve looking  last year  model  i ve sort looking across time  i ve trying find society see might better saner idea help creative people sort manage inherent emotional risk creativity ',\n",
       " 41: ' and search led ancient greece ancient rome ',\n",
       " 42: 'so stay  circle around back ',\n",
       " 43: 'but  ancient greece ancient rome  people happen believe creativity came human being back  ok people believed creativity divine attendant spirit came human being distant unknowable source  distant unknowable reason the greeks famously called divine attendant spirit creativity  daemon  ',\n",
       " 44: 'socrates  famously  believed daemon spoke wisdom afar ',\n",
       " 45: ' the romans idea  called sort disembodied creative spirit genius ',\n",
       " 46: 'which great  romans actually think genius particularly clever individual ',\n",
       " 47: 'they believed genius  sort magical divine entity  believed literally live wall artist s studio  kind like dobby house elf  would come sort invisibly assist artist work would shape outcome work ',\n",
       " 48: ' so brilliant   right  distance i m talking  psychological construct protect result work ',\n",
       " 49: 'and everyone knew functioned  right ',\n",
       " 50: 'so ancient artist protected certain thing  like  example  much narcissism  right ',\n",
       " 51: 'if work brilliant  could nt take credit  everybody knew disembodied genius helped if work bombed  entirely fault  know ',\n",
       " 52: 'everyone knew genius kind lame ',\n",
       " 53: '  laughter   and people thought creativity west really long time ',\n",
       " 54: 'and renaissance came everything changed  big idea  big idea  let s put individual human center universe god mystery  s room mystical creature take dictation divine ',\n",
       " 55: 'and s beginning rational humanism  people started believe creativity came completely self individual ',\n",
       " 56: 'and first time history  start hear people referring artist genius  rather genius ',\n",
       " 57: ' and i got tell  i think huge error ',\n",
       " 58: 'you know  i think allowing somebody  one mere person believe like  vessel  know  like font essence source divine  creative  unknowable  eternal mystery smidge much responsibility put one fragile  human psyche ',\n",
       " 59: 'it s like asking somebody swallow sun ',\n",
       " 60: 'it completely warp distorts ego  creates unmanageable expectation performance ',\n",
       " 61: 'and i think pressure killing artist last  year ',\n",
       " 62: ' and  true  i think true  question becomes  ',\n",
       " 63: 'can differently maybe go back ancient understanding relationship human creative mystery maybe ',\n",
       " 64: 'maybe ca nt erase  year rational humanistic thought one  minute speech and s probably people audience would raise really legitimate scientific suspicion notion  basically  fairy follow people around rubbing fairy juice project stuff ',\n",
       " 65: 'i m  probably  going bring along ',\n",
       " 66: ' but question i kind want pose  know  ',\n",
       " 67: 'why think way ',\n",
       " 68: 'because make much sense anything else i ever heard term explaining utter maddening capriciousness creative process a process  anybody ever tried make something  say basically everyone   know always behave rationally ',\n",
       " 69: 'and  fact  sometimes feel downright paranormal  i encounter recently i met extraordinary american poet ruth stone  s   s poet entire life told growing rural virginia  would working field  said would feel hear poem coming landscape ',\n",
       " 70: 'and said like thunderous train air ',\n",
       " 71: 'and would come barreling landscape ',\n",
       " 72: 'and felt coming  would shake earth foot she knew one thing point   word   run like hell  and would run like hell house would getting chased poem  whole deal get piece paper pencil fast enough thundered  could collect grab page ',\n",
       " 73: 'and time would nt fast enough  d running running  would nt get house poem would barrel would miss said would continue across landscape  looking  put  another poet  and time  piece i never forgot  said moment would almost miss  right ',\n",
       " 74: 'so  s running house s looking paper poem pass  grab pencil s going  said  like would reach hand would catch ',\n",
       " 75: 'she would catch poem tail  would pull backwards body transcribing page ',\n",
       " 76: 'and instance  poem would come page perfect intact backwards  last word first ',\n",
       " 77: '  laughter   so i heard i like  s uncanny  s exactly creative process like   laughter   that s creative process  i m pipeline ',\n",
       " 78: 'i m mule  way i work i get time every day  sweat labor barrel really awkwardly ',\n",
       " 79: 'but even i  mulishness  even i brushed thing  time ',\n",
       " 80: 'and i would imagine lot ',\n",
       " 81: 'you know  even i work idea come source i honestly identify ',\n",
       " 82: 'and thing ',\n",
       " 83: 'and relate way make u lose mind   fact  might actually keep u sane ',\n",
       " 84: ' and  best contemporary example i musician tom waits  i got interview several year ago magazine assignment ',\n",
       " 85: 'and talking  know  tom  life  pretty much embodiment tormented contemporary modern artist  trying control manage dominate sort uncontrollable creative impulse totally internalized ',\n",
       " 86: ' but got older  got calmer  one day driving freeway los angeles  changed ',\n",
       " 87: 'and s speeding along  sudden hears little fragment melody  come head inspiration often come  elusive tantalizing  want  s gorgeous  longs  way get he nt piece paper  pencil  tape recorder  so start feel old anxiety start rise like   i m going lose thing  i ll haunted song forever i m good enough  i ca nt  ',\n",
       " 88: 'and instead panicking  stopped ',\n",
       " 89: 'he stopped whole mental process something completely novel ',\n",
       " 90: 'he looked sky  said   excuse  see i m driving    laughter    do i look like i write song right ',\n",
       " 91: 'if really want exist  come back opportune moment i take care ',\n",
       " 92: 'otherwise  go bother somebody else today ',\n",
       " 93: 'go bother leonard cohen  ',\n",
       " 94: ' and whole work process changed ',\n",
       " 95: 'not work  work still oftentimes dark ever ',\n",
       " 96: 'but process  heavy anxiety around released took genie  genius causing nothing trouble  released back came  realized nt internalized  tormented thing ',\n",
       " 97: 'it could peculiar  wondrous  bizarre collaboration  kind conversation tom strange  external thing quite tom ',\n",
       " 98: ' when i heard story  started shift little bit way i worked  idea already saved ',\n",
       " 99: 'it saved i middle writing  eat  pray  love   i fell one sort pit despair fall re working something s coming start think going disaster  worst book ever written not bad  worst book ever written ',\n",
       " 100: 'and i started think i dump project ',\n",
       " 101: 'but i remembered tom talking open air i tried ',\n",
       " 102: 'so i lifted face manuscript i directed comment empty corner room ',\n",
       " 103: 'and i said aloud   listen  thing  i know book nt brilliant entirely fault  right because see i putting everything i  i nt ',\n",
       " 104: 'if want better  ve got show part deal ',\n",
       " 105: 'but nt  know  hell ',\n",
       " 106: 'i m going keep writing anyway s job and i would please like record reflect today i showed part job  ',\n",
       " 107: '  laughter   because    applause   because end s like  ok  century ago desert north africa  people used gather moonlight dance sacred dance music would go hour hour  dawn ',\n",
       " 108: 'they always magnificent  dancer professional terrific  right ',\n",
       " 109: 'but every  rarely  something would happen  one performer would actually become transcendent ',\n",
       " 110: 'and i know know i m talking  i know ve seen  point life  performance like it like time would stop  dancer would sort step kind portal nt anything different ever done   night  everything would align ',\n",
       " 111: 'and sudden  would longer appear merely human ',\n",
       " 112: 'he would lit within  lit lit fire divinity ',\n",
       " 113: ' and happened  back  people knew  know  called name ',\n",
       " 114: 'they would put hand together would start chant   allah  allah  allah  god  god  god  that s god  know curious historical footnote  moors invaded southern spain  took custom pronunciation changed century  allah  allah  allah    olé  olé  olé   still hear bullfight flamenco dance ',\n",
       " 115: 'in spain  performer done something impossible magic   allah  olé  olé  allah  magnificent  bravo   incomprehensible   glimpse god ',\n",
       " 116: 'which great  need ',\n",
       " 117: ' but  tricky bit come next morning  dancer  wake discovers s tuesday  am  s longer glimpse god ',\n",
       " 118: 'he s aging mortal really bad knee  maybe s never going ascend height ',\n",
       " 119: 'and maybe nobody ever chant god s name spin  rest life ',\n",
       " 120: 'this hard ',\n",
       " 121: 'this one painful reconciliation make creative life ',\n",
       " 122: 'but maybe nt quite full anguish never happened believe  first place  extraordinary aspect came but maybe believed loan unimaginable source exquisite portion life passed along re finished  somebody else ',\n",
       " 123: 'and  know  think way  start change everything ',\n",
       " 124: ' this i ve started think  certainly i ve thinking last month i ve working book soon published  dangerously  frighteningly overanticipated follow freakish success  and i sort keep telling i get really psyched nt afraid ',\n",
       " 125: 'do nt daunted ',\n",
       " 126: 'just job ',\n",
       " 127: 'continue show piece  whatever might ',\n",
       " 128: 'if job dance  dance ',\n",
       " 129: 'if divine  cockeyed genius assigned case decides let sort wonderment glimpsed  one moment effort   olé  ',\n",
       " 130: 'and  dance anyhow ',\n",
       " 131: 'and  olé  ',\n",
       " 132: ' nonetheless ',\n",
       " 133: 'i believe i feel must teach ',\n",
       " 134: ' olé  ',\n",
       " 135: ' nonetheless  sheer human love stubbornness keep showing  thank   applause   thank ',\n",
       " 136: '  applause   june cohen  olé   applause '}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "sentences = \"\"\n",
    "corpus = pd.read_pickle(\"corpus.pkl\")\n",
    "corpus\n",
    "i=0\n",
    "a=0\n",
    "j=1\n",
    "b=0\n",
    "merged_sentences = []\n",
    "unique_topics = []\n",
    "time_and_sentences = pd.read_pickle('time_and_sentences.pkl')\n",
    "keys = list(time_and_sentences.keys())\n",
    "values = list(time_and_sentences.values())\n",
    "to_minus = []\n",
    "\n",
    "\n",
    "while(a<len(sent_topics_df)-1):\n",
    "    sentences = data_clean.loc[a].at['transcript']\n",
    "    if(sent_topics_df.loc[a].at[\"Dom_Topic\"] == sent_topics_df.loc[a+1].at[\"Dom_Topic\"]):\n",
    "        while((a<len(sent_topics_df)-1) and (sent_topics_df.loc[a].at[\"Dom_Topic\"] == sent_topics_df.loc[a+1].at[\"Dom_Topic\"])):\n",
    "            sentences += data_clean.loc[a+1].at['transcript']\n",
    "            b+=1\n",
    "            j+=1\n",
    "            a+=1\n",
    "        merged_sentences.append(a)\n",
    "        to_minus.append(b)\n",
    "    unique_topics.append(sent_topics_df.loc[a].at['Dom_Topic'])\n",
    "    data[i] = sentences\n",
    "    i+=1\n",
    "    a+=1\n",
    "if(a<len(sent_topics_df)):\n",
    "    data[i] = sentences = data_clean.loc[a].at['transcript']\n",
    "    unique_topics.append(sent_topics_df.loc[a].at['Dom_Topic'])\n",
    "\n",
    "\n",
    "values.sort()\n",
    "\n",
    "pickle.dump(time_and_sentences, open(\"time_and_sentences.pkl\", \"wb\" ))\n",
    "\n",
    "time_and_sentences = dict(zip(keys, values))\n",
    "pickle.dump(time_and_sentences, open(\"time_and_sentences.pkl\", \"wb\" ))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7062680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 15, 16, 28, 34, 40, 47, 48, 52, 58, 61, 67, 71, 76, 83, 88, 99, 100, 107, 109, 112, 117, 121, 125, 137, 144, 150, 158, 159, 171, 172, 173, 174]\n",
      "[0, 9, 14, 15, 26, 30, 34, 40, 41, 45, 50, 53, 58, 62, 67, 72, 75, 84, 84, 91, 93, 96, 99, 103, 107, 116, 122, 127, 134, 134, 146, 146, 147, 147]\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "j=0\n",
    "a=0\n",
    "print(values)\n",
    "while(i < len(values)):\n",
    "    while(j < len(merged_sentences) and merged_sentences[j] <= values[i]):\n",
    "        a+=1\n",
    "        j+=1\n",
    "        \n",
    "    values[i] = values[i] - a\n",
    "    a=0\n",
    "    j=0\n",
    "    i+=1\n",
    "\n",
    "time_and_sentences = dict(zip(keys, values))\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dd1204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to change this to key: sentence_id, value: string format\n",
    "def combine_text(list_of_text):\n",
    "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
    "    combined_text = ''.join(list_of_text)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5eb6005f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [' i writer '],\n",
       " 1: ['writing book profession s  course '],\n",
       " 2: ['it also great lifelong love fascination '],\n",
       " 3: ['and i nt expect s ever going change '],\n",
       " 4: ['but  said  something kind peculiar happened recently life career  caused recalibrate whole relationship work '],\n",
       " 5: ['and peculiar thing i recently wrote book  memoir called  eat  pray  love   decidedly unlike previous book  went world reason  became big  megasensation  international bestseller thing the result everywhere i go  people treat like i m doomed '],\n",
       " 6: ['seriously  doomed  doomed '],\n",
       " 7: ['like  come  worried  say   are nt afraid re never going able top '],\n",
       " 8: ['are nt afraid re going keep writing whole life re never going create book anybody world care  ever  '],\n",
       " 9: [' so s reassuring  know '],\n",
       " 10: ['but would worse  except i happen remember  year ago  i teenager  i first started telling people i wanted writer  i met sort fearbased reaction '],\n",
       " 11: ['and people would say   are nt afraid re never going success '],\n",
       " 12: ['are nt afraid humiliation rejection kill '],\n",
       " 13: ['are nt afraid re going work whole life craft nothing s ever going come re going die scrap heap broken dream mouth filled bitter ash failure  '],\n",
       " 14: ['  laughter   like  know '],\n",
       " 15: [' the answer  short answer question   yes  '],\n",
       " 16: ['yes  i m afraid thing '],\n",
       " 17: ['and i always '],\n",
       " 18: ['and i m afraid many  many thing besides people ca nt even guess  like seaweed thing scary '],\n",
       " 19: ['but  come writing  thing i ve sort thinking lately  wondering lately  '],\n",
       " 20: ['you know  rational is logical anybody expected afraid work feel put earth and specifically creative venture seems make u really nervous s mental health way career kind nt  know '],\n",
       " 21: ['like dad  example  chemical engineer i nt recall  year chemical engineering anybody asking afraid chemical engineer  know '],\n",
       " 22: [' that chemicalengineering block  john  s going  '],\n",
       " 23: ['it nt come like  know but fair  chemical engineer group nt really earned reputation century alcoholic manicdepressive   laughter   we writer  kind reputation  writer  creative people across genre  seems  reputation enormously mentally unstable and look grim death count  century alone  really magnificent creative mind died young often hand  know '],\n",
       " 24: ['and even one nt literally commit suicide seem really undone gift  know norman mailer  died  last interview  said   every one book killed little  '],\n",
       " 25: ['an extraordinary statement make life s work '],\n",
       " 26: ['but nt even blink hear somebody say  ve heard kind stuff long somehow ve completely internalized accepted collectively notion creativity suffering somehow inherently linked artistry  end  always ultimately lead anguish '],\n",
       " 27: [' and question i want ask everybody today guy cool idea '],\n",
       " 28: ['are comfortable because look even inch away  know  i m comfortable assumption '],\n",
       " 29: ['i think s odious '],\n",
       " 30: ['and i also think s dangerous  i nt want see perpetuated next century i think s better encourage great creative mind live  and i definitely know  case  situation  would dangerous start sort leaking dark path assumption  particularly given circumstance i m right career '],\n",
       " 31: ['which  know  like check  i m pretty young  i m  year old '],\n",
       " 32: ['i still maybe another four decade work left and s exceedingly likely anything i write point forward going judged world work came freakish success last book  right '],\n",
       " 33: ['i put bluntly  re sort friend  s exceedingly likely greatest success behind '],\n",
       " 34: ['so jesus  thought '],\n",
       " 35: ['that s kind thought could lead person start drinking gin nine oclock morning  i nt want go '],\n",
       " 36: ['  laughter   i would prefer keep work i love '],\n",
       " 37: [' and  question becomes  '],\n",
       " 38: ['and  seems  upon lot reflection  way i work  order continue writing  i create sort protective psychological construct  right '],\n",
       " 39: ['i sort find way safe distance  i writing  natural anxiety reaction writing going  '],\n",
       " 40: ['and  i ve looking  last year  model  i ve sort looking across time  i ve trying find society see might better saner idea help creative people sort manage inherent emotional risk creativity '],\n",
       " 41: [' and search led ancient greece ancient rome '],\n",
       " 42: ['so stay  circle around back '],\n",
       " 43: ['but  ancient greece ancient rome  people happen believe creativity came human being back  ok people believed creativity divine attendant spirit came human being distant unknowable source  distant unknowable reason the greeks famously called divine attendant spirit creativity  daemon  '],\n",
       " 44: ['socrates  famously  believed daemon spoke wisdom afar '],\n",
       " 45: [' the romans idea  called sort disembodied creative spirit genius '],\n",
       " 46: ['which great  romans actually think genius particularly clever individual '],\n",
       " 47: ['they believed genius  sort magical divine entity  believed literally live wall artist s studio  kind like dobby house elf  would come sort invisibly assist artist work would shape outcome work '],\n",
       " 48: [' so brilliant   right  distance i m talking  psychological construct protect result work '],\n",
       " 49: ['and everyone knew functioned  right '],\n",
       " 50: ['so ancient artist protected certain thing  like  example  much narcissism  right '],\n",
       " 51: ['if work brilliant  could nt take credit  everybody knew disembodied genius helped if work bombed  entirely fault  know '],\n",
       " 52: ['everyone knew genius kind lame '],\n",
       " 53: ['  laughter   and people thought creativity west really long time '],\n",
       " 54: ['and renaissance came everything changed  big idea  big idea  let s put individual human center universe god mystery  s room mystical creature take dictation divine '],\n",
       " 55: ['and s beginning rational humanism  people started believe creativity came completely self individual '],\n",
       " 56: ['and first time history  start hear people referring artist genius  rather genius '],\n",
       " 57: [' and i got tell  i think huge error '],\n",
       " 58: ['you know  i think allowing somebody  one mere person believe like  vessel  know  like font essence source divine  creative  unknowable  eternal mystery smidge much responsibility put one fragile  human psyche '],\n",
       " 59: ['it s like asking somebody swallow sun '],\n",
       " 60: ['it completely warp distorts ego  creates unmanageable expectation performance '],\n",
       " 61: ['and i think pressure killing artist last  year '],\n",
       " 62: [' and  true  i think true  question becomes  '],\n",
       " 63: ['can differently maybe go back ancient understanding relationship human creative mystery maybe '],\n",
       " 64: ['maybe ca nt erase  year rational humanistic thought one  minute speech and s probably people audience would raise really legitimate scientific suspicion notion  basically  fairy follow people around rubbing fairy juice project stuff '],\n",
       " 65: ['i m  probably  going bring along '],\n",
       " 66: [' but question i kind want pose  know  '],\n",
       " 67: ['why think way '],\n",
       " 68: ['because make much sense anything else i ever heard term explaining utter maddening capriciousness creative process a process  anybody ever tried make something  say basically everyone   know always behave rationally '],\n",
       " 69: ['and  fact  sometimes feel downright paranormal  i encounter recently i met extraordinary american poet ruth stone  s   s poet entire life told growing rural virginia  would working field  said would feel hear poem coming landscape '],\n",
       " 70: ['and said like thunderous train air '],\n",
       " 71: ['and would come barreling landscape '],\n",
       " 72: ['and felt coming  would shake earth foot she knew one thing point   word   run like hell  and would run like hell house would getting chased poem  whole deal get piece paper pencil fast enough thundered  could collect grab page '],\n",
       " 73: ['and time would nt fast enough  d running running  would nt get house poem would barrel would miss said would continue across landscape  looking  put  another poet  and time  piece i never forgot  said moment would almost miss  right '],\n",
       " 74: ['so  s running house s looking paper poem pass  grab pencil s going  said  like would reach hand would catch '],\n",
       " 75: ['she would catch poem tail  would pull backwards body transcribing page '],\n",
       " 76: ['and instance  poem would come page perfect intact backwards  last word first '],\n",
       " 77: ['  laughter   so i heard i like  s uncanny  s exactly creative process like   laughter   that s creative process  i m pipeline '],\n",
       " 78: ['i m mule  way i work i get time every day  sweat labor barrel really awkwardly '],\n",
       " 79: ['but even i  mulishness  even i brushed thing  time '],\n",
       " 80: ['and i would imagine lot '],\n",
       " 81: ['you know  even i work idea come source i honestly identify '],\n",
       " 82: ['and thing '],\n",
       " 83: ['and relate way make u lose mind   fact  might actually keep u sane '],\n",
       " 84: [' and  best contemporary example i musician tom waits  i got interview several year ago magazine assignment '],\n",
       " 85: ['and talking  know  tom  life  pretty much embodiment tormented contemporary modern artist  trying control manage dominate sort uncontrollable creative impulse totally internalized '],\n",
       " 86: [' but got older  got calmer  one day driving freeway los angeles  changed '],\n",
       " 87: ['and s speeding along  sudden hears little fragment melody  come head inspiration often come  elusive tantalizing  want  s gorgeous  longs  way get he nt piece paper  pencil  tape recorder  so start feel old anxiety start rise like   i m going lose thing  i ll haunted song forever i m good enough  i ca nt  '],\n",
       " 88: ['and instead panicking  stopped '],\n",
       " 89: ['he stopped whole mental process something completely novel '],\n",
       " 90: ['he looked sky  said   excuse  see i m driving    laughter    do i look like i write song right '],\n",
       " 91: ['if really want exist  come back opportune moment i take care '],\n",
       " 92: ['otherwise  go bother somebody else today '],\n",
       " 93: ['go bother leonard cohen  '],\n",
       " 94: [' and whole work process changed '],\n",
       " 95: ['not work  work still oftentimes dark ever '],\n",
       " 96: ['but process  heavy anxiety around released took genie  genius causing nothing trouble  released back came  realized nt internalized  tormented thing '],\n",
       " 97: ['it could peculiar  wondrous  bizarre collaboration  kind conversation tom strange  external thing quite tom '],\n",
       " 98: [' when i heard story  started shift little bit way i worked  idea already saved '],\n",
       " 99: ['it saved i middle writing  eat  pray  love   i fell one sort pit despair fall re working something s coming start think going disaster  worst book ever written not bad  worst book ever written '],\n",
       " 100: ['and i started think i dump project '],\n",
       " 101: ['but i remembered tom talking open air i tried '],\n",
       " 102: ['so i lifted face manuscript i directed comment empty corner room '],\n",
       " 103: ['and i said aloud   listen  thing  i know book nt brilliant entirely fault  right because see i putting everything i  i nt '],\n",
       " 104: ['if want better  ve got show part deal '],\n",
       " 105: ['but nt  know  hell '],\n",
       " 106: ['i m going keep writing anyway s job and i would please like record reflect today i showed part job  '],\n",
       " 107: ['  laughter   because    applause   because end s like  ok  century ago desert north africa  people used gather moonlight dance sacred dance music would go hour hour  dawn '],\n",
       " 108: ['they always magnificent  dancer professional terrific  right '],\n",
       " 109: ['but every  rarely  something would happen  one performer would actually become transcendent '],\n",
       " 110: ['and i know know i m talking  i know ve seen  point life  performance like it like time would stop  dancer would sort step kind portal nt anything different ever done   night  everything would align '],\n",
       " 111: ['and sudden  would longer appear merely human '],\n",
       " 112: ['he would lit within  lit lit fire divinity '],\n",
       " 113: [' and happened  back  people knew  know  called name '],\n",
       " 114: ['they would put hand together would start chant   allah  allah  allah  god  god  god  that s god  know curious historical footnote  moors invaded southern spain  took custom pronunciation changed century  allah  allah  allah    olé  olé  olé   still hear bullfight flamenco dance '],\n",
       " 115: ['in spain  performer done something impossible magic   allah  olé  olé  allah  magnificent  bravo   incomprehensible   glimpse god '],\n",
       " 116: ['which great  need '],\n",
       " 117: [' but  tricky bit come next morning  dancer  wake discovers s tuesday  am  s longer glimpse god '],\n",
       " 118: ['he s aging mortal really bad knee  maybe s never going ascend height '],\n",
       " 119: ['and maybe nobody ever chant god s name spin  rest life '],\n",
       " 120: ['this hard '],\n",
       " 121: ['this one painful reconciliation make creative life '],\n",
       " 122: ['but maybe nt quite full anguish never happened believe  first place  extraordinary aspect came but maybe believed loan unimaginable source exquisite portion life passed along re finished  somebody else '],\n",
       " 123: ['and  know  think way  start change everything '],\n",
       " 124: [' this i ve started think  certainly i ve thinking last month i ve working book soon published  dangerously  frighteningly overanticipated follow freakish success  and i sort keep telling i get really psyched nt afraid '],\n",
       " 125: ['do nt daunted '],\n",
       " 126: ['just job '],\n",
       " 127: ['continue show piece  whatever might '],\n",
       " 128: ['if job dance  dance '],\n",
       " 129: ['if divine  cockeyed genius assigned case decides let sort wonderment glimpsed  one moment effort   olé  '],\n",
       " 130: ['and  dance anyhow '],\n",
       " 131: ['and  olé  '],\n",
       " 132: [' nonetheless '],\n",
       " 133: ['i believe i feel must teach '],\n",
       " 134: [' olé  '],\n",
       " 135: [' nonetheless  sheer human love stubbornness keep showing  thank   applause   thank '],\n",
       " 136: ['  applause   june cohen  olé   applause ']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine it!\n",
    "data_combined = {key: [combine_text(value)] for (key, value) in data.items()}\n",
    "data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e9dd9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>writing book profession s  course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it also great lifelong love fascination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and i nt expect s ever going change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>but  said  something kind peculiar happened recently life career  caused recalibrate whole relationship work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>nonetheless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>i believe i feel must teach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>olé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>nonetheless  sheer human love stubbornness keep showing  thank   applause   thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>applause   june cohen  olé   applause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        transcript\n",
       "0                                                                                                        i writer \n",
       "1                                                                               writing book profession s  course \n",
       "2                                                                         it also great lifelong love fascination \n",
       "3                                                                             and i nt expect s ever going change \n",
       "4    but  said  something kind peculiar happened recently life career  caused recalibrate whole relationship work \n",
       "..                                                                                                             ...\n",
       "132                                                                                                   nonetheless \n",
       "133                                                                                   i believe i feel must teach \n",
       "134                                                                                                          olé  \n",
       "135                             nonetheless  sheer human love stubbornness keep showing  thank   applause   thank \n",
       "136                                                                         applause   june cohen  olé   applause \n",
       "\n",
       "[137 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can either keep it in dictionary format or put it into a pandas dataframe\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "combined_sent = pd.DataFrame.from_dict(data_combined).transpose()\n",
    "combined_sent.columns = ['transcript']\n",
    "combined_sent = combined_sent.sort_index()\n",
    "combined_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bcaa867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle it for later use\n",
    "combined_sent.to_pickle(\"Combined_wrt_topics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4222af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00:00': 0,\n",
       " '01:07': 9,\n",
       " '01:39': 14,\n",
       " '01:42': 15,\n",
       " '02:53': 26,\n",
       " '03:53': 30,\n",
       " '04:17': 34,\n",
       " '05:11': 40,\n",
       " '05:14': 41,\n",
       " '05:58': 45,\n",
       " '06:35': 50,\n",
       " '07:05': 53,\n",
       " '07:34': 58,\n",
       " '08:10': 62,\n",
       " '08:47': 67,\n",
       " '09:30': 72,\n",
       " '09:59': 75,\n",
       " '11:31': 84,\n",
       " '11:40': 84,\n",
       " '12:17': 91,\n",
       " '12:41': 93,\n",
       " '13:05': 96,\n",
       " '13:26': 99,\n",
       " '13:44': 103,\n",
       " '14:14': 107,\n",
       " '15:17': 116,\n",
       " '16:14': 122,\n",
       " '16:58': 127,\n",
       " '17:55': 134,\n",
       " '18:09': 134,\n",
       " '18:51': 146,\n",
       " '18:53': 146,\n",
       " '18:56': 147,\n",
       " '19:01': 147}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_and_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
